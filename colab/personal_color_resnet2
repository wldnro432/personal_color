{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"mount_file_id":"1xZR4Jx8BPl5Oq_UswWB5_b1pIncRCzJ0","authorship_tag":"ABX9TyMJpA30q6g4yYoLblVDRR3N"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["#resnet50 사용"],"metadata":{"id":"MAgUrFNcCVWp"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VGPF4Eoi4rhu","executionInfo":{"status":"ok","timestamp":1683081395726,"user_tz":-540,"elapsed":14,"user":{"displayName":"박민수","userId":"07044323519487942912"}},"outputId":"844c03fc-b699-4eeb-c9ca-819a35c5ef0c"},"outputs":[{"output_type":"stream","name":"stdout","text":["[Errno 2] No such file or directory: 'drive/MyDrive'\n","/content\n"]}],"source":["%cd drive/MyDrive"]},{"cell_type":"code","source":["!git clone https://github.com/sebastianbk/finetuned-resnet50-keras.git"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ES8bFyac4uvj","executionInfo":{"status":"ok","timestamp":1682434614407,"user_tz":-540,"elapsed":1844,"user":{"displayName":"박민수","userId":"07044323519487942912"}},"outputId":"1a622491-05c3-44f3-cbc5-f27dd59f31ef"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'finetuned-resnet50-keras'...\n","remote: Enumerating objects: 12, done.\u001b[K\n","remote: Total 12 (delta 0), reused 0 (delta 0), pack-reused 12\u001b[K\n","Unpacking objects: 100% (12/12), 2.71 KiB | 16.00 KiB/s, done.\n"]}]},{"cell_type":"code","source":["%cd drive/MyDrive/finetuned-resnet50-keras/"],"metadata":{"id":"ZVRXLCYq6rzG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683102736949,"user_tz":-540,"elapsed":295,"user":{"displayName":"박민수","userId":"07044323519487942912"}},"outputId":"07dd5ccc-b508-4d04-e57c-a0c3ee0dabf5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/finetuned-resnet50-keras\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"EY9pKkoNCUKy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 톤을 먼저 나누기"],"metadata":{"id":"KH_RS--cCZhi"}},{"cell_type":"markdown","source":["### tone\n"],"metadata":{"id":"JL3wTkxgb8d-"}},{"cell_type":"code","source":["import tensorflow as tf\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.models import Model,Sequential\n","\n","from keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","train_path = '../color_data2/color_data_tone/train/'\n","val_path = '../color_data2/val_tone/'\n","\n","# 예측할 클래스 수\n","classes = 2\n","\n","# Input으로 사용될 크기와 채널수\n","height = 256\n","width = 256\n","channels = 3\n","\n","\n","image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255,\n","                                                                  rotation_range = 45,\n","                                                                  width_shift_range = 0.2,\n","                                                                  height_shift_range = 0.2,\n","                                                                  shear_range = 0.2,\n","                                                                  zoom_range = 0.7,\n","                                                                  horizontal_flip = True,\n","                                                                  validation_split=0.33,)\n","\n","image_data_train = image_generator.flow_from_directory(train_path,subset='training')\n","image_data_test = image_generator.flow_from_directory(val_path,subset='validation')\n","\n","print(image_data_train.class_indices)\n","\n","resnetv2 = tf.keras.applications.ResNet152V2(include_top=False,input_shape=(height,width,channels))\n","\n","\n","resnetv2.trainable=False\n","\n","\n","model = Sequential([\n","                 resnetv2,\n","                 Dense(512,activation='relu'),\n","                 BatchNormalization(),\n","                 GlobalAveragePooling2D(),\n","                 Dense(classes,activation='softmax')\n","])\n","\n","model.compile(optimizer='adam',loss='categorical_crossentropy',metrics='accuracy')\n","\n","def scheduler(epoch, lr):\n","    if epoch < 2:\n","        return lr\n","    else:\n","        return lr * tf.math.exp(-0.1)\n","\n","lrs = tf.keras.callbacks.LearningRateScheduler(scheduler)\n","\n","# model.fit(image_data_train,batch_size=32,epochs=10,callbacks=[lrs],validation_data=(image_data_test),\n","#           validation_steps =image_data_test.samples/image_data_test.batch_size)\n","\n","early_stopping = EarlyStopping(patience=10)\n","checkpointer = ModelCheckpoint('resnet152v2_tone_best.h5', verbose=1, save_best_only=True)\n","\n","model.fit(image_data_train,batch_size=256,epochs=30, callbacks=[lrs, early_stopping, checkpointer],validation_data=(image_data_test),\n","          validation_steps =image_data_test.samples/image_data_test.batch_size)\n","model.save('resnet152v2_tone_final.h5')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PgHu_bBbzU-k","executionInfo":{"status":"ok","timestamp":1683094199358,"user_tz":-540,"elapsed":368672,"user":{"displayName":"박민수","userId":"07044323519487942912"}},"outputId":"fc5f6650-88ed-428e-9c66-e8dcfb6ee02d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 279 images belonging to 2 classes.\n","Found 136 images belonging to 2 classes.\n","{'cool': 0, 'warm': 1}\n","Epoch 1/30\n","9/9 [==============================] - ETA: 0s - loss: 0.8251 - accuracy: 0.5376\n","Epoch 1: val_loss improved from inf to 0.91937, saving model to resnet152v2_tone_best.h5\n","9/9 [==============================] - 27s 2s/step - loss: 0.8251 - accuracy: 0.5376 - val_loss: 0.9194 - val_accuracy: 0.5221 - lr: 0.0010\n","Epoch 2/30\n","9/9 [==============================] - ETA: 0s - loss: 0.6915 - accuracy: 0.6595\n","Epoch 2: val_loss did not improve from 0.91937\n","9/9 [==============================] - 9s 1s/step - loss: 0.6915 - accuracy: 0.6595 - val_loss: 0.9320 - val_accuracy: 0.5368 - lr: 0.0010\n","Epoch 3/30\n","9/9 [==============================] - ETA: 0s - loss: 0.6739 - accuracy: 0.6595\n","Epoch 3: val_loss improved from 0.91937 to 0.80456, saving model to resnet152v2_tone_best.h5\n","9/9 [==============================] - 12s 1s/step - loss: 0.6739 - accuracy: 0.6595 - val_loss: 0.8046 - val_accuracy: 0.6029 - lr: 9.0484e-04\n","Epoch 4/30\n","9/9 [==============================] - ETA: 0s - loss: 0.6037 - accuracy: 0.6631\n","Epoch 4: val_loss did not improve from 0.80456\n","9/9 [==============================] - 10s 1s/step - loss: 0.6037 - accuracy: 0.6631 - val_loss: 0.8207 - val_accuracy: 0.5735 - lr: 8.1873e-04\n","Epoch 5/30\n","9/9 [==============================] - ETA: 0s - loss: 0.5547 - accuracy: 0.7204\n","Epoch 5: val_loss improved from 0.80456 to 0.73233, saving model to resnet152v2_tone_best.h5\n","9/9 [==============================] - 14s 2s/step - loss: 0.5547 - accuracy: 0.7204 - val_loss: 0.7323 - val_accuracy: 0.6176 - lr: 7.4082e-04\n","Epoch 6/30\n","9/9 [==============================] - ETA: 0s - loss: 0.5769 - accuracy: 0.7097\n","Epoch 6: val_loss improved from 0.73233 to 0.69588, saving model to resnet152v2_tone_best.h5\n","9/9 [==============================] - 13s 1s/step - loss: 0.5769 - accuracy: 0.7097 - val_loss: 0.6959 - val_accuracy: 0.6397 - lr: 6.7032e-04\n","Epoch 7/30\n","9/9 [==============================] - ETA: 0s - loss: 0.5513 - accuracy: 0.6953\n","Epoch 7: val_loss did not improve from 0.69588\n","9/9 [==============================] - 11s 1s/step - loss: 0.5513 - accuracy: 0.6953 - val_loss: 0.7119 - val_accuracy: 0.6691 - lr: 6.0653e-04\n","Epoch 8/30\n","9/9 [==============================] - ETA: 0s - loss: 0.4789 - accuracy: 0.7778\n","Epoch 8: val_loss improved from 0.69588 to 0.69360, saving model to resnet152v2_tone_best.h5\n","9/9 [==============================] - 14s 2s/step - loss: 0.4789 - accuracy: 0.7778 - val_loss: 0.6936 - val_accuracy: 0.6544 - lr: 5.4881e-04\n","Epoch 9/30\n","9/9 [==============================] - ETA: 0s - loss: 0.4807 - accuracy: 0.7706\n","Epoch 9: val_loss did not improve from 0.69360\n","9/9 [==============================] - 9s 1s/step - loss: 0.4807 - accuracy: 0.7706 - val_loss: 0.7883 - val_accuracy: 0.5515 - lr: 4.9659e-04\n","Epoch 10/30\n","9/9 [==============================] - ETA: 0s - loss: 0.4931 - accuracy: 0.7276\n","Epoch 10: val_loss improved from 0.69360 to 0.68003, saving model to resnet152v2_tone_best.h5\n","9/9 [==============================] - 13s 1s/step - loss: 0.4931 - accuracy: 0.7276 - val_loss: 0.6800 - val_accuracy: 0.6618 - lr: 4.4933e-04\n","Epoch 11/30\n","9/9 [==============================] - ETA: 0s - loss: 0.5112 - accuracy: 0.7563\n","Epoch 11: val_loss did not improve from 0.68003\n","9/9 [==============================] - 9s 1s/step - loss: 0.5112 - accuracy: 0.7563 - val_loss: 0.7450 - val_accuracy: 0.6176 - lr: 4.0657e-04\n","Epoch 12/30\n","9/9 [==============================] - ETA: 0s - loss: 0.5257 - accuracy: 0.7348\n","Epoch 12: val_loss improved from 0.68003 to 0.62573, saving model to resnet152v2_tone_best.h5\n","9/9 [==============================] - 12s 1s/step - loss: 0.5257 - accuracy: 0.7348 - val_loss: 0.6257 - val_accuracy: 0.6544 - lr: 3.6788e-04\n","Epoch 13/30\n","9/9 [==============================] - ETA: 0s - loss: 0.4736 - accuracy: 0.7706\n","Epoch 13: val_loss did not improve from 0.62573\n","9/9 [==============================] - 11s 1s/step - loss: 0.4736 - accuracy: 0.7706 - val_loss: 0.7630 - val_accuracy: 0.5882 - lr: 3.3287e-04\n","Epoch 14/30\n","9/9 [==============================] - ETA: 0s - loss: 0.4978 - accuracy: 0.7384\n","Epoch 14: val_loss did not improve from 0.62573\n","9/9 [==============================] - 9s 1s/step - loss: 0.4978 - accuracy: 0.7384 - val_loss: 0.6523 - val_accuracy: 0.6471 - lr: 3.0119e-04\n","Epoch 15/30\n","9/9 [==============================] - ETA: 0s - loss: 0.4460 - accuracy: 0.7885\n","Epoch 15: val_loss improved from 0.62573 to 0.62479, saving model to resnet152v2_tone_best.h5\n","9/9 [==============================] - 13s 1s/step - loss: 0.4460 - accuracy: 0.7885 - val_loss: 0.6248 - val_accuracy: 0.6471 - lr: 2.7253e-04\n","Epoch 16/30\n","9/9 [==============================] - ETA: 0s - loss: 0.4175 - accuracy: 0.8029\n","Epoch 16: val_loss did not improve from 0.62479\n","9/9 [==============================] - 11s 1s/step - loss: 0.4175 - accuracy: 0.8029 - val_loss: 0.6514 - val_accuracy: 0.6397 - lr: 2.4660e-04\n","Epoch 17/30\n","9/9 [==============================] - ETA: 0s - loss: 0.4085 - accuracy: 0.8172\n","Epoch 17: val_loss did not improve from 0.62479\n","9/9 [==============================] - 8s 929ms/step - loss: 0.4085 - accuracy: 0.8172 - val_loss: 0.7121 - val_accuracy: 0.6103 - lr: 2.2313e-04\n","Epoch 18/30\n","9/9 [==============================] - ETA: 0s - loss: 0.4605 - accuracy: 0.7563\n","Epoch 18: val_loss did not improve from 0.62479\n","9/9 [==============================] - 9s 1s/step - loss: 0.4605 - accuracy: 0.7563 - val_loss: 0.6839 - val_accuracy: 0.5882 - lr: 2.0190e-04\n","Epoch 19/30\n","9/9 [==============================] - ETA: 0s - loss: 0.4893 - accuracy: 0.7814\n","Epoch 19: val_loss improved from 0.62479 to 0.61999, saving model to resnet152v2_tone_best.h5\n","9/9 [==============================] - 13s 1s/step - loss: 0.4893 - accuracy: 0.7814 - val_loss: 0.6200 - val_accuracy: 0.6691 - lr: 1.8268e-04\n","Epoch 20/30\n","9/9 [==============================] - ETA: 0s - loss: 0.4286 - accuracy: 0.8208\n","Epoch 20: val_loss did not improve from 0.61999\n","9/9 [==============================] - 9s 994ms/step - loss: 0.4286 - accuracy: 0.8208 - val_loss: 0.6726 - val_accuracy: 0.6544 - lr: 1.6530e-04\n","Epoch 21/30\n","9/9 [==============================] - ETA: 0s - loss: 0.5313 - accuracy: 0.7240\n","Epoch 21: val_loss did not improve from 0.61999\n","9/9 [==============================] - 10s 953ms/step - loss: 0.5313 - accuracy: 0.7240 - val_loss: 0.6224 - val_accuracy: 0.6838 - lr: 1.4957e-04\n","Epoch 22/30\n","9/9 [==============================] - ETA: 0s - loss: 0.4252 - accuracy: 0.8065\n","Epoch 22: val_loss did not improve from 0.61999\n","9/9 [==============================] - 9s 1s/step - loss: 0.4252 - accuracy: 0.8065 - val_loss: 0.7102 - val_accuracy: 0.6250 - lr: 1.3534e-04\n","Epoch 23/30\n","9/9 [==============================] - ETA: 0s - loss: 0.4487 - accuracy: 0.7921\n","Epoch 23: val_loss did not improve from 0.61999\n","9/9 [==============================] - 10s 1s/step - loss: 0.4487 - accuracy: 0.7921 - val_loss: 0.7316 - val_accuracy: 0.6397 - lr: 1.2246e-04\n","Epoch 24/30\n","9/9 [==============================] - ETA: 0s - loss: 0.4248 - accuracy: 0.8208\n","Epoch 24: val_loss did not improve from 0.61999\n","9/9 [==============================] - 8s 889ms/step - loss: 0.4248 - accuracy: 0.8208 - val_loss: 0.6266 - val_accuracy: 0.6544 - lr: 1.1080e-04\n","Epoch 25/30\n","9/9 [==============================] - ETA: 0s - loss: 0.4223 - accuracy: 0.8100\n","Epoch 25: val_loss did not improve from 0.61999\n","9/9 [==============================] - 9s 1s/step - loss: 0.4223 - accuracy: 0.8100 - val_loss: 0.6786 - val_accuracy: 0.6618 - lr: 1.0026e-04\n","Epoch 26/30\n","9/9 [==============================] - ETA: 0s - loss: 0.4276 - accuracy: 0.8065\n","Epoch 26: val_loss did not improve from 0.61999\n","9/9 [==============================] - 10s 1s/step - loss: 0.4276 - accuracy: 0.8065 - val_loss: 0.7185 - val_accuracy: 0.6691 - lr: 9.0718e-05\n","Epoch 27/30\n","9/9 [==============================] - ETA: 0s - loss: 0.4894 - accuracy: 0.7742\n","Epoch 27: val_loss did not improve from 0.61999\n","9/9 [==============================] - 8s 879ms/step - loss: 0.4894 - accuracy: 0.7742 - val_loss: 0.6397 - val_accuracy: 0.7132 - lr: 8.2085e-05\n","Epoch 28/30\n","9/9 [==============================] - ETA: 0s - loss: 0.4603 - accuracy: 0.7742\n","Epoch 28: val_loss did not improve from 0.61999\n","9/9 [==============================] - 9s 1s/step - loss: 0.4603 - accuracy: 0.7742 - val_loss: 0.6758 - val_accuracy: 0.6324 - lr: 7.4273e-05\n","Epoch 29/30\n","9/9 [==============================] - ETA: 0s - loss: 0.4275 - accuracy: 0.7885\n","Epoch 29: val_loss did not improve from 0.61999\n","9/9 [==============================] - 10s 1s/step - loss: 0.4275 - accuracy: 0.7885 - val_loss: 0.6615 - val_accuracy: 0.6324 - lr: 6.7205e-05\n"]}]},{"cell_type":"markdown","source":["## 계절을 먼저 나누기"],"metadata":{"id":"T1a_S82nC1bU"}},{"cell_type":"markdown","source":["### season"],"metadata":{"id":"Sl5S71WJeLoz"}},{"cell_type":"code","source":["import tensorflow as tf\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.models import Model,Sequential\n","\n","from keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","train_path = '../color_data2/color_data_season/train/'\n","val_path = '../color_data2/val_season/'\n","\n","# 예측할 클래스 수\n","classes = 2\n","\n","# Input으로 사용될 크기와 채널수\n","height = 256\n","width = 256\n","channels = 3\n","\n","\n","\n","image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255,\n","                                                                  rotation_range = 45,\n","                                                                  width_shift_range = 0.2,\n","                                                                  height_shift_range = 0.2,\n","                                                                  shear_range = 0.2,\n","                                                                  zoom_range = 0.7,\n","                                                                  horizontal_flip = True,\n","                                                                  validation_split=0.33,)\n","\n","image_data_train = image_generator.flow_from_directory(train_path,subset='training')\n","image_data_test = image_generator.flow_from_directory(val_path,subset='validation')\n","\n","print(image_data_train.class_indices)\n","\n","resnetv2 = tf.keras.applications.ResNet152V2(include_top=False,input_shape=(height,width,channels))\n","\n","\n","resnetv2.trainable=False\n","\n","\n","model = Sequential([\n","                 resnetv2,\n","                 Dense(512,activation='relu'),\n","                 BatchNormalization(),\n","                 GlobalAveragePooling2D(),\n","                 Dense(classes,activation='softmax')\n","])\n","\n","model.compile(optimizer='adam',loss='categorical_crossentropy',metrics='accuracy')\n","\n","def scheduler(epoch, lr):\n","    if epoch < 2:\n","        return lr\n","    else:\n","        return lr * tf.math.exp(-0.1)\n","\n","lrs = tf.keras.callbacks.LearningRateScheduler(scheduler)\n","\n","# model.fit(image_data_train,batch_size=32,epochs=10,callbacks=[lrs],validation_data=(image_data_test),\n","#           validation_steps =image_data_test.samples/image_data_test.batch_size)\n","\n","early_stopping = EarlyStopping(patience=20)\n","checkpointer = ModelCheckpoint('resnet152v2_season_best.h5', verbose=1, save_best_only=True)\n","\n","model.fit(image_data_train,batch_size=256,epochs=80, callbacks=[lrs, early_stopping, checkpointer],validation_data=(image_data_test),\n","          validation_steps =image_data_test.samples/image_data_test.batch_size)\n","model.save('resnet152v2_season_final.h5')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"USssE_4mg0Ge","executionInfo":{"status":"ok","timestamp":1683100657143,"user_tz":-540,"elapsed":621249,"user":{"displayName":"박민수","userId":"07044323519487942912"}},"outputId":"71f5400a-df25-4ea0-8a30-5cca5fd855c8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 279 images belonging to 2 classes.\n","Found 136 images belonging to 2 classes.\n","{'deep': 0, 'light': 1}\n","Epoch 1/80\n","9/9 [==============================] - ETA: 0s - loss: 0.8110 - accuracy: 0.5233\n","Epoch 1: val_loss improved from inf to 0.98577, saving model to resnet152v2_season_best.h5\n","9/9 [==============================] - 26s 2s/step - loss: 0.8110 - accuracy: 0.5233 - val_loss: 0.9858 - val_accuracy: 0.5441 - lr: 0.0010\n","Epoch 2/80\n","9/9 [==============================] - ETA: 0s - loss: 0.7795 - accuracy: 0.6165\n","Epoch 2: val_loss improved from 0.98577 to 0.86844, saving model to resnet152v2_season_best.h5\n","9/9 [==============================] - 12s 1s/step - loss: 0.7795 - accuracy: 0.6165 - val_loss: 0.8684 - val_accuracy: 0.5956 - lr: 0.0010\n","Epoch 3/80\n","9/9 [==============================] - ETA: 0s - loss: 0.6981 - accuracy: 0.6487\n","Epoch 3: val_loss improved from 0.86844 to 0.79485, saving model to resnet152v2_season_best.h5\n","9/9 [==============================] - 10s 1s/step - loss: 0.6981 - accuracy: 0.6487 - val_loss: 0.7949 - val_accuracy: 0.5809 - lr: 9.0484e-04\n","Epoch 4/80\n","9/9 [==============================] - ETA: 0s - loss: 0.6955 - accuracy: 0.6165\n","Epoch 4: val_loss did not improve from 0.79485\n","9/9 [==============================] - 10s 1s/step - loss: 0.6955 - accuracy: 0.6165 - val_loss: 0.9633 - val_accuracy: 0.5368 - lr: 8.1873e-04\n","Epoch 5/80\n","9/9 [==============================] - ETA: 0s - loss: 0.6099 - accuracy: 0.6810\n","Epoch 5: val_loss did not improve from 0.79485\n","9/9 [==============================] - 8s 874ms/step - loss: 0.6099 - accuracy: 0.6810 - val_loss: 1.0721 - val_accuracy: 0.5294 - lr: 7.4082e-04\n","Epoch 6/80\n","9/9 [==============================] - ETA: 0s - loss: 0.6783 - accuracy: 0.6810\n","Epoch 6: val_loss did not improve from 0.79485\n","9/9 [==============================] - 9s 1s/step - loss: 0.6783 - accuracy: 0.6810 - val_loss: 0.9379 - val_accuracy: 0.5074 - lr: 6.7032e-04\n","Epoch 7/80\n","9/9 [==============================] - ETA: 0s - loss: 0.5962 - accuracy: 0.6595\n","Epoch 7: val_loss did not improve from 0.79485\n","9/9 [==============================] - 8s 944ms/step - loss: 0.5962 - accuracy: 0.6595 - val_loss: 0.8844 - val_accuracy: 0.5588 - lr: 6.0653e-04\n","Epoch 8/80\n","9/9 [==============================] - ETA: 0s - loss: 0.5652 - accuracy: 0.7204\n","Epoch 8: val_loss did not improve from 0.79485\n","9/9 [==============================] - 8s 894ms/step - loss: 0.5652 - accuracy: 0.7204 - val_loss: 0.7991 - val_accuracy: 0.5588 - lr: 5.4881e-04\n","Epoch 9/80\n","9/9 [==============================] - ETA: 0s - loss: 0.5363 - accuracy: 0.7097\n","Epoch 9: val_loss did not improve from 0.79485\n","9/9 [==============================] - 9s 1000ms/step - loss: 0.5363 - accuracy: 0.7097 - val_loss: 0.8038 - val_accuracy: 0.5882 - lr: 4.9659e-04\n","Epoch 10/80\n","9/9 [==============================] - ETA: 0s - loss: 0.6131 - accuracy: 0.6667\n","Epoch 10: val_loss improved from 0.79485 to 0.77011, saving model to resnet152v2_season_best.h5\n","9/9 [==============================] - 12s 1s/step - loss: 0.6131 - accuracy: 0.6667 - val_loss: 0.7701 - val_accuracy: 0.5956 - lr: 4.4933e-04\n","Epoch 11/80\n","9/9 [==============================] - ETA: 0s - loss: 0.5586 - accuracy: 0.7133\n","Epoch 11: val_loss did not improve from 0.77011\n","9/9 [==============================] - 8s 870ms/step - loss: 0.5586 - accuracy: 0.7133 - val_loss: 0.7913 - val_accuracy: 0.6176 - lr: 4.0657e-04\n","Epoch 12/80\n","9/9 [==============================] - ETA: 0s - loss: 0.5693 - accuracy: 0.6953\n","Epoch 12: val_loss did not improve from 0.77011\n","9/9 [==============================] - 9s 1s/step - loss: 0.5693 - accuracy: 0.6953 - val_loss: 0.8638 - val_accuracy: 0.5147 - lr: 3.6788e-04\n","Epoch 13/80\n","9/9 [==============================] - ETA: 0s - loss: 0.5682 - accuracy: 0.6989\n","Epoch 13: val_loss improved from 0.77011 to 0.76124, saving model to resnet152v2_season_best.h5\n","9/9 [==============================] - 12s 1s/step - loss: 0.5682 - accuracy: 0.6989 - val_loss: 0.7612 - val_accuracy: 0.5809 - lr: 3.3287e-04\n","Epoch 14/80\n","9/9 [==============================] - ETA: 0s - loss: 0.5328 - accuracy: 0.7168\n","Epoch 14: val_loss did not improve from 0.76124\n","9/9 [==============================] - 10s 1s/step - loss: 0.5328 - accuracy: 0.7168 - val_loss: 0.7938 - val_accuracy: 0.5588 - lr: 3.0119e-04\n","Epoch 15/80\n","9/9 [==============================] - ETA: 0s - loss: 0.5596 - accuracy: 0.7276\n","Epoch 15: val_loss did not improve from 0.76124\n","9/9 [==============================] - 9s 969ms/step - loss: 0.5596 - accuracy: 0.7276 - val_loss: 0.8017 - val_accuracy: 0.5515 - lr: 2.7253e-04\n","Epoch 16/80\n","9/9 [==============================] - ETA: 0s - loss: 0.5257 - accuracy: 0.7491\n","Epoch 16: val_loss improved from 0.76124 to 0.69595, saving model to resnet152v2_season_best.h5\n","9/9 [==============================] - 12s 1s/step - loss: 0.5257 - accuracy: 0.7491 - val_loss: 0.6960 - val_accuracy: 0.6103 - lr: 2.4660e-04\n","Epoch 17/80\n","9/9 [==============================] - ETA: 0s - loss: 0.4954 - accuracy: 0.7599\n","Epoch 17: val_loss did not improve from 0.69595\n","9/9 [==============================] - 8s 960ms/step - loss: 0.4954 - accuracy: 0.7599 - val_loss: 0.8032 - val_accuracy: 0.5368 - lr: 2.2313e-04\n","Epoch 18/80\n","9/9 [==============================] - ETA: 0s - loss: 0.5182 - accuracy: 0.7204\n","Epoch 18: val_loss did not improve from 0.69595\n","9/9 [==============================] - 9s 1s/step - loss: 0.5182 - accuracy: 0.7204 - val_loss: 0.7800 - val_accuracy: 0.5588 - lr: 2.0190e-04\n","Epoch 19/80\n","9/9 [==============================] - ETA: 0s - loss: 0.5108 - accuracy: 0.7240\n","Epoch 19: val_loss did not improve from 0.69595\n","9/9 [==============================] - 8s 902ms/step - loss: 0.5108 - accuracy: 0.7240 - val_loss: 0.8166 - val_accuracy: 0.6029 - lr: 1.8268e-04\n","Epoch 20/80\n","9/9 [==============================] - ETA: 0s - loss: 0.5040 - accuracy: 0.7312\n","Epoch 20: val_loss did not improve from 0.69595\n","9/9 [==============================] - 8s 878ms/step - loss: 0.5040 - accuracy: 0.7312 - val_loss: 0.7038 - val_accuracy: 0.6103 - lr: 1.6530e-04\n","Epoch 21/80\n","9/9 [==============================] - ETA: 0s - loss: 0.4864 - accuracy: 0.7491\n","Epoch 21: val_loss did not improve from 0.69595\n","9/9 [==============================] - 10s 1s/step - loss: 0.4864 - accuracy: 0.7491 - val_loss: 0.7693 - val_accuracy: 0.5441 - lr: 1.4957e-04\n","Epoch 22/80\n","9/9 [==============================] - ETA: 0s - loss: 0.5396 - accuracy: 0.7276\n","Epoch 22: val_loss did not improve from 0.69595\n","9/9 [==============================] - 9s 978ms/step - loss: 0.5396 - accuracy: 0.7276 - val_loss: 0.7830 - val_accuracy: 0.5515 - lr: 1.3534e-04\n","Epoch 23/80\n","9/9 [==============================] - ETA: 0s - loss: 0.4789 - accuracy: 0.7778\n","Epoch 23: val_loss did not improve from 0.69595\n","9/9 [==============================] - 8s 866ms/step - loss: 0.4789 - accuracy: 0.7778 - val_loss: 0.7453 - val_accuracy: 0.5368 - lr: 1.2246e-04\n","Epoch 24/80\n","9/9 [==============================] - ETA: 0s - loss: 0.5093 - accuracy: 0.7527\n","Epoch 24: val_loss improved from 0.69595 to 0.65795, saving model to resnet152v2_season_best.h5\n","9/9 [==============================] - 12s 1s/step - loss: 0.5093 - accuracy: 0.7527 - val_loss: 0.6580 - val_accuracy: 0.6618 - lr: 1.1080e-04\n","Epoch 25/80\n","9/9 [==============================] - ETA: 0s - loss: 0.4845 - accuracy: 0.7634\n","Epoch 25: val_loss did not improve from 0.65795\n","9/9 [==============================] - 9s 991ms/step - loss: 0.4845 - accuracy: 0.7634 - val_loss: 0.6888 - val_accuracy: 0.6029 - lr: 1.0026e-04\n","Epoch 26/80\n","9/9 [==============================] - ETA: 0s - loss: 0.4556 - accuracy: 0.7849\n","Epoch 26: val_loss did not improve from 0.65795\n","9/9 [==============================] - 9s 961ms/step - loss: 0.4556 - accuracy: 0.7849 - val_loss: 0.7536 - val_accuracy: 0.5735 - lr: 9.0718e-05\n","Epoch 27/80\n","9/9 [==============================] - ETA: 0s - loss: 0.5141 - accuracy: 0.7563\n","Epoch 27: val_loss did not improve from 0.65795\n","9/9 [==============================] - 8s 931ms/step - loss: 0.5141 - accuracy: 0.7563 - val_loss: 0.7357 - val_accuracy: 0.6176 - lr: 8.2085e-05\n","Epoch 28/80\n","9/9 [==============================] - ETA: 0s - loss: 0.5177 - accuracy: 0.7599\n","Epoch 28: val_loss did not improve from 0.65795\n","9/9 [==============================] - 9s 1s/step - loss: 0.5177 - accuracy: 0.7599 - val_loss: 0.7202 - val_accuracy: 0.5294 - lr: 7.4273e-05\n","Epoch 29/80\n","9/9 [==============================] - ETA: 0s - loss: 0.5290 - accuracy: 0.7097\n","Epoch 29: val_loss did not improve from 0.65795\n","9/9 [==============================] - 8s 876ms/step - loss: 0.5290 - accuracy: 0.7097 - val_loss: 0.6949 - val_accuracy: 0.5809 - lr: 6.7205e-05\n","Epoch 30/80\n","9/9 [==============================] - ETA: 0s - loss: 0.4953 - accuracy: 0.7455\n","Epoch 30: val_loss did not improve from 0.65795\n","9/9 [==============================] - 9s 1s/step - loss: 0.4953 - accuracy: 0.7455 - val_loss: 0.7804 - val_accuracy: 0.5441 - lr: 6.0810e-05\n","Epoch 31/80\n","9/9 [==============================] - ETA: 0s - loss: 0.4892 - accuracy: 0.7599\n","Epoch 31: val_loss did not improve from 0.65795\n","9/9 [==============================] - 9s 991ms/step - loss: 0.4892 - accuracy: 0.7599 - val_loss: 0.8313 - val_accuracy: 0.5515 - lr: 5.5023e-05\n","Epoch 32/80\n","9/9 [==============================] - ETA: 0s - loss: 0.4739 - accuracy: 0.7921\n","Epoch 32: val_loss did not improve from 0.65795\n","9/9 [==============================] - 8s 878ms/step - loss: 0.4739 - accuracy: 0.7921 - val_loss: 0.7488 - val_accuracy: 0.5515 - lr: 4.9787e-05\n","Epoch 33/80\n","9/9 [==============================] - ETA: 0s - loss: 0.5138 - accuracy: 0.7061\n","Epoch 33: val_loss did not improve from 0.65795\n","9/9 [==============================] - 9s 1s/step - loss: 0.5138 - accuracy: 0.7061 - val_loss: 0.7825 - val_accuracy: 0.5221 - lr: 4.5049e-05\n","Epoch 34/80\n","9/9 [==============================] - ETA: 0s - loss: 0.5160 - accuracy: 0.7168\n","Epoch 34: val_loss did not improve from 0.65795\n","9/9 [==============================] - 10s 1s/step - loss: 0.5160 - accuracy: 0.7168 - val_loss: 0.7562 - val_accuracy: 0.5809 - lr: 4.0762e-05\n","Epoch 35/80\n","9/9 [==============================] - ETA: 0s - loss: 0.4742 - accuracy: 0.7849\n","Epoch 35: val_loss did not improve from 0.65795\n","9/9 [==============================] - 8s 888ms/step - loss: 0.4742 - accuracy: 0.7849 - val_loss: 0.7411 - val_accuracy: 0.6029 - lr: 3.6883e-05\n","Epoch 36/80\n","9/9 [==============================] - ETA: 0s - loss: 0.5187 - accuracy: 0.7563\n","Epoch 36: val_loss did not improve from 0.65795\n","9/9 [==============================] - 9s 1s/step - loss: 0.5187 - accuracy: 0.7563 - val_loss: 0.6970 - val_accuracy: 0.5809 - lr: 3.3373e-05\n","Epoch 37/80\n","9/9 [==============================] - ETA: 0s - loss: 0.4826 - accuracy: 0.7599\n","Epoch 37: val_loss did not improve from 0.65795\n","9/9 [==============================] - 9s 977ms/step - loss: 0.4826 - accuracy: 0.7599 - val_loss: 0.8134 - val_accuracy: 0.5147 - lr: 3.0197e-05\n","Epoch 38/80\n","9/9 [==============================] - ETA: 0s - loss: 0.4740 - accuracy: 0.7814\n","Epoch 38: val_loss did not improve from 0.65795\n","9/9 [==============================] - 8s 866ms/step - loss: 0.4740 - accuracy: 0.7814 - val_loss: 0.6801 - val_accuracy: 0.6250 - lr: 2.7324e-05\n","Epoch 39/80\n","9/9 [==============================] - ETA: 0s - loss: 0.5044 - accuracy: 0.7670\n","Epoch 39: val_loss did not improve from 0.65795\n","9/9 [==============================] - 9s 990ms/step - loss: 0.5044 - accuracy: 0.7670 - val_loss: 0.7682 - val_accuracy: 0.5735 - lr: 2.4723e-05\n","Epoch 40/80\n","9/9 [==============================] - ETA: 0s - loss: 0.5042 - accuracy: 0.7276\n","Epoch 40: val_loss improved from 0.65795 to 0.65396, saving model to resnet152v2_season_best.h5\n","9/9 [==============================] - 11s 1s/step - loss: 0.5042 - accuracy: 0.7276 - val_loss: 0.6540 - val_accuracy: 0.6691 - lr: 2.2371e-05\n","Epoch 41/80\n","9/9 [==============================] - ETA: 0s - loss: 0.5039 - accuracy: 0.7384\n","Epoch 41: val_loss did not improve from 0.65396\n","9/9 [==============================] - 10s 1s/step - loss: 0.5039 - accuracy: 0.7384 - val_loss: 0.6965 - val_accuracy: 0.6103 - lr: 2.0242e-05\n","Epoch 42/80\n","9/9 [==============================] - ETA: 0s - loss: 0.4733 - accuracy: 0.7814\n","Epoch 42: val_loss did not improve from 0.65396\n","9/9 [==============================] - 9s 947ms/step - loss: 0.4733 - accuracy: 0.7814 - val_loss: 0.7048 - val_accuracy: 0.6176 - lr: 1.8316e-05\n","Epoch 43/80\n","9/9 [==============================] - ETA: 0s - loss: 0.4790 - accuracy: 0.7742\n","Epoch 43: val_loss did not improve from 0.65396\n","9/9 [==============================] - 9s 1s/step - loss: 0.4790 - accuracy: 0.7742 - val_loss: 0.7017 - val_accuracy: 0.5956 - lr: 1.6573e-05\n","Epoch 44/80\n","9/9 [==============================] - ETA: 0s - loss: 0.5034 - accuracy: 0.7527\n","Epoch 44: val_loss did not improve from 0.65396\n","9/9 [==============================] - 8s 880ms/step - loss: 0.5034 - accuracy: 0.7527 - val_loss: 0.7162 - val_accuracy: 0.6103 - lr: 1.4996e-05\n","Epoch 45/80\n","9/9 [==============================] - ETA: 0s - loss: 0.4859 - accuracy: 0.7849\n","Epoch 45: val_loss did not improve from 0.65396\n","9/9 [==============================] - 8s 902ms/step - loss: 0.4859 - accuracy: 0.7849 - val_loss: 0.7322 - val_accuracy: 0.6103 - lr: 1.3569e-05\n","Epoch 46/80\n","9/9 [==============================] - ETA: 0s - loss: 0.4949 - accuracy: 0.7742\n","Epoch 46: val_loss did not improve from 0.65396\n","9/9 [==============================] - 9s 1s/step - loss: 0.4949 - accuracy: 0.7742 - val_loss: 0.8212 - val_accuracy: 0.6029 - lr: 1.2277e-05\n","Epoch 47/80\n","9/9 [==============================] - ETA: 0s - loss: 0.4413 - accuracy: 0.7993\n","Epoch 47: val_loss did not improve from 0.65396\n","9/9 [==============================] - 10s 1s/step - loss: 0.4413 - accuracy: 0.7993 - val_loss: 0.7672 - val_accuracy: 0.6324 - lr: 1.1109e-05\n","Epoch 48/80\n","9/9 [==============================] - ETA: 0s - loss: 0.4577 - accuracy: 0.7814\n","Epoch 48: val_loss did not improve from 0.65396\n","9/9 [==============================] - 8s 943ms/step - loss: 0.4577 - accuracy: 0.7814 - val_loss: 0.7002 - val_accuracy: 0.5956 - lr: 1.0052e-05\n","Epoch 49/80\n","9/9 [==============================] - ETA: 0s - loss: 0.4811 - accuracy: 0.7670\n","Epoch 49: val_loss did not improve from 0.65396\n","9/9 [==============================] - 9s 1s/step - loss: 0.4811 - accuracy: 0.7670 - val_loss: 0.7320 - val_accuracy: 0.5956 - lr: 9.0953e-06\n","Epoch 50/80\n","9/9 [==============================] - ETA: 0s - loss: 0.4707 - accuracy: 0.7742\n","Epoch 50: val_loss did not improve from 0.65396\n","9/9 [==============================] - 8s 864ms/step - loss: 0.4707 - accuracy: 0.7742 - val_loss: 0.7403 - val_accuracy: 0.6103 - lr: 8.2297e-06\n","Epoch 51/80\n","9/9 [==============================] - ETA: 0s - loss: 0.4502 - accuracy: 0.7957\n","Epoch 51: val_loss did not improve from 0.65396\n","9/9 [==============================] - 8s 861ms/step - loss: 0.4502 - accuracy: 0.7957 - val_loss: 0.7537 - val_accuracy: 0.5588 - lr: 7.4466e-06\n","Epoch 52/80\n","9/9 [==============================] - ETA: 0s - loss: 0.4611 - accuracy: 0.7921\n","Epoch 52: val_loss did not improve from 0.65396\n","9/9 [==============================] - 9s 992ms/step - loss: 0.4611 - accuracy: 0.7921 - val_loss: 0.6909 - val_accuracy: 0.6691 - lr: 6.7379e-06\n","Epoch 53/80\n","9/9 [==============================] - ETA: 0s - loss: 0.4509 - accuracy: 0.7885\n","Epoch 53: val_loss did not improve from 0.65396\n","9/9 [==============================] - 10s 1s/step - loss: 0.4509 - accuracy: 0.7885 - val_loss: 0.7302 - val_accuracy: 0.6029 - lr: 6.0967e-06\n","Epoch 54/80\n","9/9 [==============================] - ETA: 0s - loss: 0.4931 - accuracy: 0.7885\n","Epoch 54: val_loss did not improve from 0.65396\n","9/9 [==============================] - 8s 861ms/step - loss: 0.4931 - accuracy: 0.7885 - val_loss: 0.7251 - val_accuracy: 0.6324 - lr: 5.5165e-06\n","Epoch 55/80\n","9/9 [==============================] - ETA: 0s - loss: 0.5223 - accuracy: 0.7527\n","Epoch 55: val_loss did not improve from 0.65396\n","9/9 [==============================] - 9s 1s/step - loss: 0.5223 - accuracy: 0.7527 - val_loss: 0.6930 - val_accuracy: 0.6176 - lr: 4.9916e-06\n","Epoch 56/80\n","9/9 [==============================] - ETA: 0s - loss: 0.4856 - accuracy: 0.7634\n","Epoch 56: val_loss did not improve from 0.65396\n","9/9 [==============================] - 8s 944ms/step - loss: 0.4856 - accuracy: 0.7634 - val_loss: 0.6588 - val_accuracy: 0.6765 - lr: 4.5166e-06\n","Epoch 57/80\n","9/9 [==============================] - ETA: 0s - loss: 0.5040 - accuracy: 0.7133\n","Epoch 57: val_loss did not improve from 0.65396\n","9/9 [==============================] - 8s 875ms/step - loss: 0.5040 - accuracy: 0.7133 - val_loss: 0.7812 - val_accuracy: 0.5515 - lr: 4.0868e-06\n","Epoch 58/80\n","9/9 [==============================] - ETA: 0s - loss: 0.4716 - accuracy: 0.7921\n","Epoch 58: val_loss did not improve from 0.65396\n","9/9 [==============================] - 9s 1s/step - loss: 0.4716 - accuracy: 0.7921 - val_loss: 0.7013 - val_accuracy: 0.6324 - lr: 3.6979e-06\n","Epoch 59/80\n","9/9 [==============================] - ETA: 0s - loss: 0.4508 - accuracy: 0.8029\n","Epoch 59: val_loss did not improve from 0.65396\n","9/9 [==============================] - 10s 1s/step - loss: 0.4508 - accuracy: 0.8029 - val_loss: 0.6888 - val_accuracy: 0.6029 - lr: 3.3460e-06\n","Epoch 60/80\n","9/9 [==============================] - ETA: 0s - loss: 0.4759 - accuracy: 0.7563\n","Epoch 60: val_loss did not improve from 0.65396\n","9/9 [==============================] - 8s 861ms/step - loss: 0.4759 - accuracy: 0.7563 - val_loss: 0.6813 - val_accuracy: 0.6103 - lr: 3.0275e-06\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"_nEG46DLSUKi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pwd"],"metadata":{"id":"tJB5TfPESUP5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683093048248,"user_tz":-540,"elapsed":278,"user":{"displayName":"박민수","userId":"07044323519487942912"}},"outputId":"d8e98315-bdce-4438-fa1e-c50c938c75cc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/finetuned-resnet50-keras\n"]}]},{"cell_type":"markdown","source":["## 톤을 먼저 나누고 계절을 나누기"],"metadata":{"id":"4zhZfQdJEASC"}},{"cell_type":"markdown","source":["### spring/autumn season"],"metadata":{"id":"JNYHduB5EIw0"}},{"cell_type":"code","source":["import tensorflow as tf\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.models import Model,Sequential\n","\n","from keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","train_path = '../color_data3/season_warm/train/'\n","val_path = '../color_data3/season_warm/val/'\n","\n","# 예측할 클래스 수\n","classes = 2\n","\n","# Input으로 사용될 크기와 채널수\n","height = 256\n","width = 256\n","channels = 3\n","\n","\n","\n","image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255,\n","                                                                  rotation_range = 45,\n","                                                                  width_shift_range = 0.2,\n","                                                                  height_shift_range = 0.2,\n","                                                                  shear_range = 0.2,\n","                                                                  zoom_range = 0.7,\n","                                                                  horizontal_flip = True,\n","                                                                  validation_split=0.33,)\n","\n","image_data_train = image_generator.flow_from_directory(train_path,subset='training')\n","image_data_test = image_generator.flow_from_directory(val_path,subset='validation')\n","\n","print(image_data_train.class_indices)\n","\n","resnetv2 = tf.keras.applications.ResNet152V2(include_top=False,input_shape=(height,width,channels))\n","\n","\n","resnetv2.trainable=False\n","\n","\n","model = Sequential([\n","                 resnetv2,\n","                 Dense(512,activation='relu'),\n","                 BatchNormalization(),\n","                 GlobalAveragePooling2D(),\n","                 Dense(classes,activation='softmax')\n","])\n","\n","model.compile(optimizer='adam',loss='categorical_crossentropy',metrics='accuracy')\n","\n","def scheduler(epoch, lr):\n","    if epoch < 2:\n","        return lr\n","    else:\n","        return lr * tf.math.exp(-0.1)\n","\n","lrs = tf.keras.callbacks.LearningRateScheduler(scheduler)\n","\n","# model.fit(image_data_train,batch_size=32,epochs=10,callbacks=[lrs],validation_data=(image_data_test),\n","#           validation_steps =image_data_test.samples/image_data_test.batch_size)\n","\n","early_stopping = EarlyStopping(patience=20)\n","checkpointer = ModelCheckpoint('resnet152v2_season_spring_autumn_best.h5', verbose=1, save_best_only=True)\n","\n","model.fit(image_data_train,batch_size=128,epochs=70, callbacks=[lrs, early_stopping, checkpointer],validation_data=(image_data_test),\n","          validation_steps =image_data_test.samples/image_data_test.batch_size)\n","model.save('resnet152v2_season_spring_autumn_final.h5')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HtOpAspuEAcX","executionInfo":{"status":"ok","timestamp":1683098176494,"user_tz":-540,"elapsed":244553,"user":{"displayName":"박민수","userId":"07044323519487942912"}},"outputId":"8aeb8a41-fc3b-426f-9e26-33b44acd789e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 129 images belonging to 2 classes.\n","Found 70 images belonging to 2 classes.\n","{'autumn': 0, 'spring': 1}\n","Epoch 1/70\n","5/5 [==============================] - ETA: 0s - loss: 0.7862 - accuracy: 0.5426\n","Epoch 1: val_loss improved from inf to 1.74668, saving model to resnet152v2_season_spring_autumn_best.h5\n","5/5 [==============================] - 21s 2s/step - loss: 0.7862 - accuracy: 0.5426 - val_loss: 1.7467 - val_accuracy: 0.4571 - lr: 0.0010\n","Epoch 2/70\n","5/5 [==============================] - ETA: 0s - loss: 0.6475 - accuracy: 0.6822\n","Epoch 2: val_loss improved from 1.74668 to 1.33063, saving model to resnet152v2_season_spring_autumn_best.h5\n","5/5 [==============================] - 6s 1s/step - loss: 0.6475 - accuracy: 0.6822 - val_loss: 1.3306 - val_accuracy: 0.5429 - lr: 0.0010\n","Epoch 3/70\n","5/5 [==============================] - ETA: 0s - loss: 0.7706 - accuracy: 0.6202\n","Epoch 3: val_loss did not improve from 1.33063\n","5/5 [==============================] - 6s 1s/step - loss: 0.7706 - accuracy: 0.6202 - val_loss: 1.7096 - val_accuracy: 0.5429 - lr: 9.0484e-04\n","Epoch 4/70\n","5/5 [==============================] - ETA: 0s - loss: 0.7447 - accuracy: 0.6977\n","Epoch 4: val_loss did not improve from 1.33063\n","5/5 [==============================] - 4s 847ms/step - loss: 0.7447 - accuracy: 0.6977 - val_loss: 1.6508 - val_accuracy: 0.5000 - lr: 8.1873e-04\n","Epoch 5/70\n","5/5 [==============================] - ETA: 0s - loss: 0.7011 - accuracy: 0.6899\n","Epoch 5: val_loss improved from 1.33063 to 1.26454, saving model to resnet152v2_season_spring_autumn_best.h5\n","5/5 [==============================] - 7s 2s/step - loss: 0.7011 - accuracy: 0.6899 - val_loss: 1.2645 - val_accuracy: 0.5571 - lr: 7.4082e-04\n","Epoch 6/70\n","5/5 [==============================] - ETA: 0s - loss: 0.6456 - accuracy: 0.6977\n","Epoch 6: val_loss improved from 1.26454 to 0.97926, saving model to resnet152v2_season_spring_autumn_best.h5\n","5/5 [==============================] - 7s 1s/step - loss: 0.6456 - accuracy: 0.6977 - val_loss: 0.9793 - val_accuracy: 0.6429 - lr: 6.7032e-04\n","Epoch 7/70\n","5/5 [==============================] - ETA: 0s - loss: 0.5202 - accuracy: 0.7984\n","Epoch 7: val_loss did not improve from 0.97926\n","5/5 [==============================] - 6s 1s/step - loss: 0.5202 - accuracy: 0.7984 - val_loss: 1.1323 - val_accuracy: 0.6143 - lr: 6.0653e-04\n","Epoch 8/70\n","4/5 [=======================>......] - ETA: 0s - loss: 0.6411 - accuracy: 0.6797\n","Epoch 8: val_loss did not improve from 0.97926\n","5/5 [==============================] - 4s 818ms/step - loss: 0.6417 - accuracy: 0.6744 - val_loss: 1.2560 - val_accuracy: 0.5143 - lr: 5.4881e-04\n","Epoch 9/70\n","4/5 [=======================>......] - ETA: 0s - loss: 0.4678 - accuracy: 0.8047\n","Epoch 9: val_loss did not improve from 0.97926\n","5/5 [==============================] - 6s 1s/step - loss: 0.4693 - accuracy: 0.8062 - val_loss: 0.9839 - val_accuracy: 0.5286 - lr: 4.9659e-04\n","Epoch 10/70\n","5/5 [==============================] - ETA: 0s - loss: 0.5887 - accuracy: 0.6977\n","Epoch 10: val_loss improved from 0.97926 to 0.97365, saving model to resnet152v2_season_spring_autumn_best.h5\n","5/5 [==============================] - 8s 2s/step - loss: 0.5887 - accuracy: 0.6977 - val_loss: 0.9737 - val_accuracy: 0.6000 - lr: 4.4933e-04\n","Epoch 11/70\n","4/5 [=======================>......] - ETA: 0s - loss: 0.5230 - accuracy: 0.7266\n","Epoch 11: val_loss improved from 0.97365 to 0.67453, saving model to resnet152v2_season_spring_autumn_best.h5\n","5/5 [==============================] - 7s 2s/step - loss: 0.5247 - accuracy: 0.7209 - val_loss: 0.6745 - val_accuracy: 0.6714 - lr: 4.0657e-04\n","Epoch 12/70\n","5/5 [==============================] - ETA: 0s - loss: 0.5193 - accuracy: 0.7287\n","Epoch 12: val_loss improved from 0.67453 to 0.53307, saving model to resnet152v2_season_spring_autumn_best.h5\n","5/5 [==============================] - 6s 2s/step - loss: 0.5193 - accuracy: 0.7287 - val_loss: 0.5331 - val_accuracy: 0.7571 - lr: 3.6788e-04\n","Epoch 13/70\n","5/5 [==============================] - ETA: 0s - loss: 0.4587 - accuracy: 0.8062\n","Epoch 13: val_loss did not improve from 0.53307\n","5/5 [==============================] - 6s 1s/step - loss: 0.4587 - accuracy: 0.8062 - val_loss: 0.6467 - val_accuracy: 0.7000 - lr: 3.3287e-04\n","Epoch 14/70\n","5/5 [==============================] - ETA: 0s - loss: 0.3986 - accuracy: 0.7984\n","Epoch 14: val_loss did not improve from 0.53307\n","5/5 [==============================] - 4s 845ms/step - loss: 0.3986 - accuracy: 0.7984 - val_loss: 0.5774 - val_accuracy: 0.6714 - lr: 3.0119e-04\n","Epoch 15/70\n","4/5 [=======================>......] - ETA: 0s - loss: 0.4862 - accuracy: 0.7188\n","Epoch 15: val_loss did not improve from 0.53307\n","5/5 [==============================] - 6s 1s/step - loss: 0.4879 - accuracy: 0.7132 - val_loss: 0.5641 - val_accuracy: 0.6857 - lr: 2.7253e-04\n","Epoch 16/70\n","5/5 [==============================] - ETA: 0s - loss: 0.5580 - accuracy: 0.7287\n","Epoch 16: val_loss did not improve from 0.53307\n","5/5 [==============================] - 4s 845ms/step - loss: 0.5580 - accuracy: 0.7287 - val_loss: 0.6128 - val_accuracy: 0.7143 - lr: 2.4660e-04\n","Epoch 17/70\n","5/5 [==============================] - ETA: 0s - loss: 0.5152 - accuracy: 0.7674\n","Epoch 17: val_loss did not improve from 0.53307\n","5/5 [==============================] - 4s 894ms/step - loss: 0.5152 - accuracy: 0.7674 - val_loss: 0.6685 - val_accuracy: 0.6571 - lr: 2.2313e-04\n","Epoch 18/70\n","5/5 [==============================] - ETA: 0s - loss: 0.4468 - accuracy: 0.8217\n","Epoch 18: val_loss improved from 0.53307 to 0.52205, saving model to resnet152v2_season_spring_autumn_best.h5\n","5/5 [==============================] - 7s 2s/step - loss: 0.4468 - accuracy: 0.8217 - val_loss: 0.5221 - val_accuracy: 0.6714 - lr: 2.0190e-04\n","Epoch 19/70\n","4/5 [=======================>......] - ETA: 0s - loss: 0.3422 - accuracy: 0.8750\n","Epoch 19: val_loss did not improve from 0.52205\n","5/5 [==============================] - 5s 1s/step - loss: 0.3449 - accuracy: 0.8760 - val_loss: 0.5963 - val_accuracy: 0.6857 - lr: 1.8268e-04\n","Epoch 20/70\n","5/5 [==============================] - ETA: 0s - loss: 0.4025 - accuracy: 0.7984\n","Epoch 20: val_loss did not improve from 0.52205\n","5/5 [==============================] - 5s 963ms/step - loss: 0.4025 - accuracy: 0.7984 - val_loss: 0.7474 - val_accuracy: 0.6286 - lr: 1.6530e-04\n","Epoch 21/70\n","5/5 [==============================] - ETA: 0s - loss: 0.4851 - accuracy: 0.7519\n","Epoch 21: val_loss did not improve from 0.52205\n","5/5 [==============================] - 4s 975ms/step - loss: 0.4851 - accuracy: 0.7519 - val_loss: 0.7119 - val_accuracy: 0.6571 - lr: 1.4957e-04\n","Epoch 22/70\n","5/5 [==============================] - ETA: 0s - loss: 0.3982 - accuracy: 0.8527\n","Epoch 22: val_loss did not improve from 0.52205\n","5/5 [==============================] - 5s 1s/step - loss: 0.3982 - accuracy: 0.8527 - val_loss: 0.6370 - val_accuracy: 0.7286 - lr: 1.3534e-04\n","Epoch 23/70\n","4/5 [=======================>......] - ETA: 0s - loss: 0.4432 - accuracy: 0.8359\n","Epoch 23: val_loss did not improve from 0.52205\n","5/5 [==============================] - 4s 800ms/step - loss: 0.4452 - accuracy: 0.8295 - val_loss: 0.6748 - val_accuracy: 0.6714 - lr: 1.2246e-04\n","Epoch 24/70\n","4/5 [=======================>......] - ETA: 0s - loss: 0.4120 - accuracy: 0.8203\n","Epoch 24: val_loss did not improve from 0.52205\n","5/5 [==============================] - 4s 802ms/step - loss: 0.4142 - accuracy: 0.8217 - val_loss: 0.5970 - val_accuracy: 0.7000 - lr: 1.1080e-04\n","Epoch 25/70\n","5/5 [==============================] - ETA: 0s - loss: 0.4036 - accuracy: 0.8140\n","Epoch 25: val_loss did not improve from 0.52205\n","5/5 [==============================] - 5s 1s/step - loss: 0.4036 - accuracy: 0.8140 - val_loss: 0.5988 - val_accuracy: 0.6714 - lr: 1.0026e-04\n","Epoch 26/70\n","5/5 [==============================] - ETA: 0s - loss: 0.4147 - accuracy: 0.8527\n","Epoch 26: val_loss did not improve from 0.52205\n","5/5 [==============================] - 4s 981ms/step - loss: 0.4147 - accuracy: 0.8527 - val_loss: 0.5611 - val_accuracy: 0.6571 - lr: 9.0718e-05\n","Epoch 27/70\n","5/5 [==============================] - ETA: 0s - loss: 0.3740 - accuracy: 0.8527\n","Epoch 27: val_loss did not improve from 0.52205\n","5/5 [==============================] - 4s 843ms/step - loss: 0.3740 - accuracy: 0.8527 - val_loss: 0.6790 - val_accuracy: 0.6286 - lr: 8.2085e-05\n","Epoch 28/70\n","5/5 [==============================] - ETA: 0s - loss: 0.4544 - accuracy: 0.7752\n","Epoch 28: val_loss did not improve from 0.52205\n","5/5 [==============================] - 5s 1s/step - loss: 0.4544 - accuracy: 0.7752 - val_loss: 0.5714 - val_accuracy: 0.7429 - lr: 7.4273e-05\n","Epoch 29/70\n","5/5 [==============================] - ETA: 0s - loss: 0.3578 - accuracy: 0.8915\n","Epoch 29: val_loss did not improve from 0.52205\n","5/5 [==============================] - 4s 839ms/step - loss: 0.3578 - accuracy: 0.8915 - val_loss: 0.6232 - val_accuracy: 0.6286 - lr: 6.7205e-05\n","Epoch 30/70\n","5/5 [==============================] - ETA: 0s - loss: 0.4780 - accuracy: 0.7829\n","Epoch 30: val_loss did not improve from 0.52205\n","5/5 [==============================] - 4s 842ms/step - loss: 0.4780 - accuracy: 0.7829 - val_loss: 0.6423 - val_accuracy: 0.6429 - lr: 6.0810e-05\n","Epoch 31/70\n","5/5 [==============================] - ETA: 0s - loss: 0.4446 - accuracy: 0.8062\n","Epoch 31: val_loss did not improve from 0.52205\n","5/5 [==============================] - 6s 1s/step - loss: 0.4446 - accuracy: 0.8062 - val_loss: 0.6012 - val_accuracy: 0.7286 - lr: 5.5023e-05\n","Epoch 32/70\n","5/5 [==============================] - ETA: 0s - loss: 0.4025 - accuracy: 0.8140\n","Epoch 32: val_loss did not improve from 0.52205\n","5/5 [==============================] - 4s 850ms/step - loss: 0.4025 - accuracy: 0.8140 - val_loss: 0.5499 - val_accuracy: 0.7714 - lr: 4.9787e-05\n","Epoch 33/70\n","4/5 [=======================>......] - ETA: 0s - loss: 0.4984 - accuracy: 0.7734\n","Epoch 33: val_loss did not improve from 0.52205\n","5/5 [==============================] - 4s 794ms/step - loss: 0.4999 - accuracy: 0.7752 - val_loss: 0.5475 - val_accuracy: 0.7286 - lr: 4.5049e-05\n","Epoch 34/70\n","5/5 [==============================] - ETA: 0s - loss: 0.4054 - accuracy: 0.7907\n","Epoch 34: val_loss did not improve from 0.52205\n","5/5 [==============================] - 5s 1s/step - loss: 0.4054 - accuracy: 0.7907 - val_loss: 0.6778 - val_accuracy: 0.6286 - lr: 4.0762e-05\n","Epoch 35/70\n","5/5 [==============================] - ETA: 0s - loss: 0.4312 - accuracy: 0.8140\n","Epoch 35: val_loss did not improve from 0.52205\n","5/5 [==============================] - 4s 845ms/step - loss: 0.4312 - accuracy: 0.8140 - val_loss: 0.6316 - val_accuracy: 0.6429 - lr: 3.6883e-05\n","Epoch 36/70\n","4/5 [=======================>......] - ETA: 0s - loss: 0.4037 - accuracy: 0.8359\n","Epoch 36: val_loss did not improve from 0.52205\n","5/5 [==============================] - 4s 785ms/step - loss: 0.4059 - accuracy: 0.8372 - val_loss: 0.6631 - val_accuracy: 0.7000 - lr: 3.3373e-05\n","Epoch 37/70\n","4/5 [=======================>......] - ETA: 0s - loss: 0.4658 - accuracy: 0.7578\n","Epoch 37: val_loss did not improve from 0.52205\n","5/5 [==============================] - 5s 966ms/step - loss: 0.4676 - accuracy: 0.7519 - val_loss: 0.5805 - val_accuracy: 0.7000 - lr: 3.0197e-05\n","Epoch 38/70\n","5/5 [==============================] - ETA: 0s - loss: 0.4286 - accuracy: 0.8217\n","Epoch 38: val_loss did not improve from 0.52205\n","5/5 [==============================] - 4s 961ms/step - loss: 0.4286 - accuracy: 0.8217 - val_loss: 0.8122 - val_accuracy: 0.6000 - lr: 2.7324e-05\n"]}]},{"cell_type":"markdown","source":["### winter/summer season"],"metadata":{"id":"KFysiZOWEL98"}},{"cell_type":"code","source":["import tensorflow as tf\n","import matplotlib.pyplot as plt\n","from tensorflow.keras.layers import *\n","from tensorflow.keras.models import Model,Sequential\n","\n","from keras.callbacks import EarlyStopping, ModelCheckpoint\n","\n","train_path = '../color_data3/season_cool/train/'\n","val_path = '../color_data3/season_cool/val/'\n","\n","# 예측할 클래스 수\n","classes = 2\n","\n","# Input으로 사용될 크기와 채널수\n","height = 256\n","width = 256\n","channels = 3\n","\n","\n","\n","image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255,\n","                                                                  rotation_range = 45,\n","                                                                  width_shift_range = 0.2,\n","                                                                  height_shift_range = 0.2,\n","                                                                  shear_range = 0.2,\n","                                                                  zoom_range = 0.7,\n","                                                                  horizontal_flip = True,\n","                                                                  validation_split=0.33,)\n","\n","image_data_train = image_generator.flow_from_directory(train_path,subset='training')\n","image_data_test = image_generator.flow_from_directory(val_path,subset='validation')\n","\n","print(image_data_train.class_indices)\n","\n","resnetv2 = tf.keras.applications.ResNet152V2(include_top=False,input_shape=(height,width,channels))\n","\n","\n","resnetv2.trainable=False\n","\n","\n","model = Sequential([\n","                 resnetv2,\n","                 Dense(512,activation='relu'),\n","                 BatchNormalization(),\n","                 GlobalAveragePooling2D(),\n","                 Dense(classes,activation='softmax')\n","])\n","\n","model.compile(optimizer='adam',loss='categorical_crossentropy',metrics='accuracy')\n","\n","def scheduler(epoch, lr):\n","    if epoch < 2:\n","        return lr\n","    else:\n","        return lr * tf.math.exp(-0.1)\n","\n","lrs = tf.keras.callbacks.LearningRateScheduler(scheduler)\n","\n","# model.fit(image_data_train,batch_size=32,epochs=10,callbacks=[lrs],validation_data=(image_data_test),\n","#           validation_steps =image_data_test.samples/image_data_test.batch_size)\n","\n","early_stopping = EarlyStopping(patience=20)\n","checkpointer = ModelCheckpoint('resnet152v2_season_winter_summer_best.h5', verbose=1, save_best_only=True)\n","\n","model.fit(image_data_train,batch_size=128,epochs=70, callbacks=[lrs, early_stopping, checkpointer],validation_data=(image_data_test),\n","          validation_steps =image_data_test.samples/image_data_test.batch_size)\n","model.save('resnet152v2_season_winter_summer_final.h5')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uWsElpSHEAgo","executionInfo":{"status":"ok","timestamp":1683098480135,"user_tz":-540,"elapsed":303651,"user":{"displayName":"박민수","userId":"07044323519487942912"}},"outputId":"eeac511b-a199-4d34-d419-fe46da61ef3e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 178 images belonging to 2 classes.\n","Found 95 images belonging to 2 classes.\n","{'summer': 0, 'winter': 1}\n","Epoch 1/70\n","6/6 [==============================] - ETA: 0s - loss: 0.7696 - accuracy: 0.5393\n","Epoch 1: val_loss improved from inf to 1.22074, saving model to resnet152v2_season_winter_summer_best.h5\n","6/6 [==============================] - 22s 2s/step - loss: 0.7696 - accuracy: 0.5393 - val_loss: 1.2207 - val_accuracy: 0.5789 - lr: 0.0010\n","Epoch 2/70\n","6/6 [==============================] - ETA: 0s - loss: 0.7093 - accuracy: 0.6067\n","Epoch 2: val_loss improved from 1.22074 to 0.95762, saving model to resnet152v2_season_winter_summer_best.h5\n","6/6 [==============================] - 10s 2s/step - loss: 0.7093 - accuracy: 0.6067 - val_loss: 0.9576 - val_accuracy: 0.5579 - lr: 0.0010\n","Epoch 3/70\n","6/6 [==============================] - ETA: 0s - loss: 0.6967 - accuracy: 0.7135\n","Epoch 3: val_loss improved from 0.95762 to 0.81602, saving model to resnet152v2_season_winter_summer_best.h5\n","6/6 [==============================] - 7s 1s/step - loss: 0.6967 - accuracy: 0.7135 - val_loss: 0.8160 - val_accuracy: 0.6632 - lr: 9.0484e-04\n","Epoch 4/70\n","6/6 [==============================] - ETA: 0s - loss: 0.6635 - accuracy: 0.6461\n","Epoch 4: val_loss did not improve from 0.81602\n","6/6 [==============================] - 6s 1s/step - loss: 0.6635 - accuracy: 0.6461 - val_loss: 0.8310 - val_accuracy: 0.6316 - lr: 8.1873e-04\n","Epoch 5/70\n","6/6 [==============================] - ETA: 0s - loss: 0.6727 - accuracy: 0.6573\n","Epoch 5: val_loss did not improve from 0.81602\n","6/6 [==============================] - 5s 899ms/step - loss: 0.6727 - accuracy: 0.6573 - val_loss: 0.9989 - val_accuracy: 0.6211 - lr: 7.4082e-04\n","Epoch 6/70\n","6/6 [==============================] - ETA: 0s - loss: 0.6616 - accuracy: 0.6854\n","Epoch 6: val_loss did not improve from 0.81602\n","6/6 [==============================] - 6s 951ms/step - loss: 0.6616 - accuracy: 0.6854 - val_loss: 1.0173 - val_accuracy: 0.5684 - lr: 6.7032e-04\n","Epoch 7/70\n","6/6 [==============================] - ETA: 0s - loss: 0.5855 - accuracy: 0.7022\n","Epoch 7: val_loss did not improve from 0.81602\n","6/6 [==============================] - 5s 895ms/step - loss: 0.5855 - accuracy: 0.7022 - val_loss: 0.9032 - val_accuracy: 0.6526 - lr: 6.0653e-04\n","Epoch 8/70\n","6/6 [==============================] - ETA: 0s - loss: 0.5387 - accuracy: 0.7022\n","Epoch 8: val_loss did not improve from 0.81602\n","6/6 [==============================] - 6s 1s/step - loss: 0.5387 - accuracy: 0.7022 - val_loss: 0.8645 - val_accuracy: 0.6105 - lr: 5.4881e-04\n","Epoch 9/70\n","6/6 [==============================] - ETA: 0s - loss: 0.5299 - accuracy: 0.7022\n","Epoch 9: val_loss did not improve from 0.81602\n","6/6 [==============================] - 5s 979ms/step - loss: 0.5299 - accuracy: 0.7022 - val_loss: 0.8275 - val_accuracy: 0.6000 - lr: 4.9659e-04\n","Epoch 10/70\n","6/6 [==============================] - ETA: 0s - loss: 0.5658 - accuracy: 0.7640\n","Epoch 10: val_loss improved from 0.81602 to 0.77776, saving model to resnet152v2_season_winter_summer_best.h5\n","6/6 [==============================] - 10s 2s/step - loss: 0.5658 - accuracy: 0.7640 - val_loss: 0.7778 - val_accuracy: 0.6211 - lr: 4.4933e-04\n","Epoch 11/70\n","6/6 [==============================] - ETA: 0s - loss: 0.5639 - accuracy: 0.7247\n","Epoch 11: val_loss improved from 0.77776 to 0.71324, saving model to resnet152v2_season_winter_summer_best.h5\n","6/6 [==============================] - 7s 1s/step - loss: 0.5639 - accuracy: 0.7247 - val_loss: 0.7132 - val_accuracy: 0.6947 - lr: 4.0657e-04\n","Epoch 12/70\n","6/6 [==============================] - ETA: 0s - loss: 0.5177 - accuracy: 0.7360\n","Epoch 12: val_loss did not improve from 0.71324\n","6/6 [==============================] - 6s 1s/step - loss: 0.5177 - accuracy: 0.7360 - val_loss: 0.7354 - val_accuracy: 0.6316 - lr: 3.6788e-04\n","Epoch 13/70\n","6/6 [==============================] - ETA: 0s - loss: 0.4883 - accuracy: 0.7921\n","Epoch 13: val_loss did not improve from 0.71324\n","6/6 [==============================] - 6s 1s/step - loss: 0.4883 - accuracy: 0.7921 - val_loss: 0.7181 - val_accuracy: 0.6947 - lr: 3.3287e-04\n","Epoch 14/70\n","6/6 [==============================] - ETA: 0s - loss: 0.5789 - accuracy: 0.6742\n","Epoch 14: val_loss did not improve from 0.71324\n","6/6 [==============================] - 6s 1s/step - loss: 0.5789 - accuracy: 0.6742 - val_loss: 0.7712 - val_accuracy: 0.6421 - lr: 3.0119e-04\n","Epoch 15/70\n","6/6 [==============================] - ETA: 0s - loss: 0.5693 - accuracy: 0.7360\n","Epoch 15: val_loss did not improve from 0.71324\n","6/6 [==============================] - 5s 902ms/step - loss: 0.5693 - accuracy: 0.7360 - val_loss: 0.7155 - val_accuracy: 0.6421 - lr: 2.7253e-04\n","Epoch 16/70\n","6/6 [==============================] - ETA: 0s - loss: 0.5192 - accuracy: 0.7416\n","Epoch 16: val_loss improved from 0.71324 to 0.59285, saving model to resnet152v2_season_winter_summer_best.h5\n","6/6 [==============================] - 9s 2s/step - loss: 0.5192 - accuracy: 0.7416 - val_loss: 0.5929 - val_accuracy: 0.6632 - lr: 2.4660e-04\n","Epoch 17/70\n","6/6 [==============================] - ETA: 0s - loss: 0.4925 - accuracy: 0.7640\n","Epoch 17: val_loss did not improve from 0.59285\n","6/6 [==============================] - 5s 894ms/step - loss: 0.4925 - accuracy: 0.7640 - val_loss: 0.8053 - val_accuracy: 0.6105 - lr: 2.2313e-04\n","Epoch 18/70\n","6/6 [==============================] - ETA: 0s - loss: 0.5710 - accuracy: 0.7416\n","Epoch 18: val_loss did not improve from 0.59285\n","6/6 [==============================] - 7s 1s/step - loss: 0.5710 - accuracy: 0.7416 - val_loss: 0.7090 - val_accuracy: 0.6000 - lr: 2.0190e-04\n","Epoch 19/70\n","6/6 [==============================] - ETA: 0s - loss: 0.5046 - accuracy: 0.7022\n","Epoch 19: val_loss did not improve from 0.59285\n","6/6 [==============================] - 5s 907ms/step - loss: 0.5046 - accuracy: 0.7022 - val_loss: 0.7940 - val_accuracy: 0.6105 - lr: 1.8268e-04\n","Epoch 20/70\n","6/6 [==============================] - ETA: 0s - loss: 0.5345 - accuracy: 0.7247\n","Epoch 20: val_loss did not improve from 0.59285\n","6/6 [==============================] - 6s 1s/step - loss: 0.5345 - accuracy: 0.7247 - val_loss: 0.7395 - val_accuracy: 0.6632 - lr: 1.6530e-04\n","Epoch 21/70\n","6/6 [==============================] - ETA: 0s - loss: 0.4730 - accuracy: 0.7416\n","Epoch 21: val_loss did not improve from 0.59285\n","6/6 [==============================] - 6s 925ms/step - loss: 0.4730 - accuracy: 0.7416 - val_loss: 0.8415 - val_accuracy: 0.5789 - lr: 1.4957e-04\n","Epoch 22/70\n","6/6 [==============================] - ETA: 0s - loss: 0.4683 - accuracy: 0.7697\n","Epoch 22: val_loss did not improve from 0.59285\n","6/6 [==============================] - 5s 901ms/step - loss: 0.4683 - accuracy: 0.7697 - val_loss: 0.7908 - val_accuracy: 0.6211 - lr: 1.3534e-04\n","Epoch 23/70\n","6/6 [==============================] - ETA: 0s - loss: 0.4733 - accuracy: 0.7528\n","Epoch 23: val_loss did not improve from 0.59285\n","6/6 [==============================] - 6s 1s/step - loss: 0.4733 - accuracy: 0.7528 - val_loss: 0.7616 - val_accuracy: 0.6000 - lr: 1.2246e-04\n","Epoch 24/70\n","6/6 [==============================] - ETA: 0s - loss: 0.4749 - accuracy: 0.7584\n","Epoch 24: val_loss did not improve from 0.59285\n","6/6 [==============================] - 6s 1s/step - loss: 0.4749 - accuracy: 0.7584 - val_loss: 0.7517 - val_accuracy: 0.6211 - lr: 1.1080e-04\n","Epoch 25/70\n","6/6 [==============================] - ETA: 0s - loss: 0.4855 - accuracy: 0.7809\n","Epoch 25: val_loss did not improve from 0.59285\n","6/6 [==============================] - 5s 892ms/step - loss: 0.4855 - accuracy: 0.7809 - val_loss: 0.7298 - val_accuracy: 0.6421 - lr: 1.0026e-04\n","Epoch 26/70\n","6/6 [==============================] - ETA: 0s - loss: 0.4876 - accuracy: 0.7640\n","Epoch 26: val_loss did not improve from 0.59285\n","6/6 [==============================] - 6s 1s/step - loss: 0.4876 - accuracy: 0.7640 - val_loss: 0.7451 - val_accuracy: 0.6211 - lr: 9.0718e-05\n","Epoch 27/70\n","6/6 [==============================] - ETA: 0s - loss: 0.5080 - accuracy: 0.7697\n","Epoch 27: val_loss did not improve from 0.59285\n","6/6 [==============================] - 5s 899ms/step - loss: 0.5080 - accuracy: 0.7697 - val_loss: 0.6779 - val_accuracy: 0.6737 - lr: 8.2085e-05\n","Epoch 28/70\n","6/6 [==============================] - ETA: 0s - loss: 0.4756 - accuracy: 0.7472\n","Epoch 28: val_loss did not improve from 0.59285\n","6/6 [==============================] - 6s 891ms/step - loss: 0.4756 - accuracy: 0.7472 - val_loss: 0.6965 - val_accuracy: 0.6211 - lr: 7.4273e-05\n","Epoch 29/70\n","6/6 [==============================] - ETA: 0s - loss: 0.5465 - accuracy: 0.7191\n","Epoch 29: val_loss did not improve from 0.59285\n","6/6 [==============================] - 5s 909ms/step - loss: 0.5465 - accuracy: 0.7191 - val_loss: 0.7660 - val_accuracy: 0.6737 - lr: 6.7205e-05\n","Epoch 30/70\n","6/6 [==============================] - ETA: 0s - loss: 0.4399 - accuracy: 0.7865\n","Epoch 30: val_loss did not improve from 0.59285\n","6/6 [==============================] - 6s 1s/step - loss: 0.4399 - accuracy: 0.7865 - val_loss: 0.6955 - val_accuracy: 0.6421 - lr: 6.0810e-05\n","Epoch 31/70\n","6/6 [==============================] - ETA: 0s - loss: 0.4924 - accuracy: 0.7360\n","Epoch 31: val_loss did not improve from 0.59285\n","6/6 [==============================] - 5s 906ms/step - loss: 0.4924 - accuracy: 0.7360 - val_loss: 0.6469 - val_accuracy: 0.6947 - lr: 5.5023e-05\n","Epoch 32/70\n","6/6 [==============================] - ETA: 0s - loss: 0.5455 - accuracy: 0.7247\n","Epoch 32: val_loss did not improve from 0.59285\n","6/6 [==============================] - 6s 1s/step - loss: 0.5455 - accuracy: 0.7247 - val_loss: 0.6753 - val_accuracy: 0.6842 - lr: 4.9787e-05\n","Epoch 33/70\n","6/6 [==============================] - ETA: 0s - loss: 0.4981 - accuracy: 0.7416\n","Epoch 33: val_loss did not improve from 0.59285\n","6/6 [==============================] - 5s 909ms/step - loss: 0.4981 - accuracy: 0.7416 - val_loss: 0.7347 - val_accuracy: 0.6526 - lr: 4.5049e-05\n","Epoch 34/70\n","6/6 [==============================] - ETA: 0s - loss: 0.4540 - accuracy: 0.8034\n","Epoch 34: val_loss did not improve from 0.59285\n","6/6 [==============================] - 6s 1s/step - loss: 0.4540 - accuracy: 0.8034 - val_loss: 0.6399 - val_accuracy: 0.6842 - lr: 4.0762e-05\n","Epoch 35/70\n","6/6 [==============================] - ETA: 0s - loss: 0.4335 - accuracy: 0.7865\n","Epoch 35: val_loss did not improve from 0.59285\n","6/6 [==============================] - 5s 895ms/step - loss: 0.4335 - accuracy: 0.7865 - val_loss: 0.7058 - val_accuracy: 0.6105 - lr: 3.6883e-05\n","Epoch 36/70\n","6/6 [==============================] - ETA: 0s - loss: 0.5163 - accuracy: 0.7584\n","Epoch 36: val_loss did not improve from 0.59285\n","6/6 [==============================] - 6s 1s/step - loss: 0.5163 - accuracy: 0.7584 - val_loss: 0.6730 - val_accuracy: 0.6632 - lr: 3.3373e-05\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"-kI7S0bNEAkC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"hZygSKfSEAoQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Sr-EZPZoEAry"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!ls ../color_data/train"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GhmJBTAk1ero","executionInfo":{"status":"ok","timestamp":1682483591344,"user_tz":-540,"elapsed":670,"user":{"displayName":"박민수","userId":"07044323519487942912"}},"outputId":"03682ef3-e9f3-450c-e08b-6d9551a18cda"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["autumn_warm  spring_warm  summer_cool  winter_cool\n"]}]},{"cell_type":"markdown","source":["## 테스트"],"metadata":{"id":"QSUJL_n4DK-L"}},{"cell_type":"markdown","source":["### 1. tone test"],"metadata":{"id":"XBKcYcK2hwwT"}},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.image import load_img\n","from tensorflow.keras.preprocessing.image import img_to_array\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","\n","from keras.models import load_model\n","\n","\n","img_height = 256\n","img_width = 256\n","\n","\n","# filename = ['../test_face/autumn_warm/face_000.jpg', \"../test_face/spring_warm/face_002.jpg\", \"../test_face/summer_cool/face_001.jpg\", \"../test_face/winter_cool/face_000.jpg\" ]\n","\n","filename = []\n","\n","path = \"../color_data2/color_tone_data_test/\"\n","img_list = os.listdir(path)\n","\n","for i in img_list:\n","  filename.append(path+i)\n","                    \n","predict_dictionary = {0:'cool',1:'warm'}\n","\n","tone_dict = {\n","    \"spring\": \"warm\",\n","    \"fall\": \"warm\",\n","    \"summer\": \"cool\",\n","    \"winter\": \"cool\"\n","}\n","\n","model_path = \"./resnet152v2_tone_best.h5\"\n","# model_path = \"./resnet50v2_final.h5\"\n","\n","model = load_model(model_path)\n","\n","answer_count = 0\n","f = 0\n","tone = 0\n","\n","a_list = []\n","f_list = []\n","\n","\n","# /color_data2/color_tone_data_test/fall (1).PNG \n","\n","for file in filename:\n","    original = load_img(file, target_size = (img_height,img_width))\n","\n","    \n","    numpy_image = img_to_array(original)\n","    plt.text(30, 10, str(file.split(\"/\")[-1]))\n","    plt.imshow(np.uint8(numpy_image))\n","    plt.show()\n","    print(\"numpy array size : \", numpy_image.shape)\n","    image_batch = np.expand_dims(numpy_image , axis = 0)\n","\n","    predict = np.argmax(model.predict(image_batch/255.))\n","\n","    print('결과 : ',predict_dictionary[predict])\n","    \n","    s1 = file.split(\"/\")[-1].split(\" \")[0]         \n","\n","    if predict_dictionary[predict] == tone_dict[s1]:\n","      tone += 1\n","    else:\n","      f += 1\n","\n","\n","print(\"answer :\", tone, \" f :\", f)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1p55GIAomvjF71Nrn9HrSNF8Nxzj_nCH2"},"id":"tC3jbPqwzVD3","executionInfo":{"status":"ok","timestamp":1683088044914,"user_tz":-540,"elapsed":27011,"user":{"displayName":"박민수","userId":"07044323519487942912"}},"outputId":"d876a90f-aa1a-4147-8ac0-61eaddb2742d"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.image import load_img\n","from tensorflow.keras.preprocessing.image import img_to_array\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","\n","from keras.models import load_model\n","\n","\n","img_height = 256\n","img_width = 256\n","\n","\n","# filename = ['../test_face/autumn_warm/face_000.jpg', \"../test_face/spring_warm/face_002.jpg\", \"../test_face/summer_cool/face_001.jpg\", \"../test_face/winter_cool/face_000.jpg\" ]\n","\n","filename = []\n","\n","path = \"../color_data2/color_tone_data_test/\"\n","img_list = os.listdir(path)\n","\n","for i in img_list:\n","  filename.append(path+i)\n","                    \n","predict_dictionary = {0:'cool',1:'warm'}\n","\n","tone_dict = {\n","    \"spring\": \"warm\",\n","    \"fall\": \"warm\",\n","    \"summer\": \"cool\",\n","    \"winter\": \"cool\"\n","}\n","\n","model_path = \"./resnet152v2_tone_best.h5\"\n","# model_path = \"./resnet50v2_final.h5\"\n","\n","model = load_model(model_path)\n","\n","answer_count = 0\n","f = 0\n","tone = 0\n","\n","a_list = []\n","f_list = []\n","\n","\n","# /color_data2/color_tone_data_test/fall (1).PNG \n","\n","for file in filename:\n","    original = load_img(file, target_size = (img_height,img_width))\n","\n","    \n","    numpy_image = img_to_array(original)\n","    plt.text(30, 10, str(file.split(\"/\")[-1]))\n","    plt.imshow(np.uint8(numpy_image))\n","    plt.show()\n","    print(\"numpy array size : \", numpy_image.shape)\n","    image_batch = np.expand_dims(numpy_image , axis = 0)\n","\n","    predict = np.argmax(model.predict(image_batch/255.))\n","\n","    print('결과 : ',predict_dictionary[predict])\n","    \n","    s1 = file.split(\"/\")[-1].split(\" \")[0]         \n","\n","    if predict_dictionary[predict] == tone_dict[s1]:\n","      tone += 1\n","    else:\n","      f += 1\n","\n","\n","print(\"answer :\", tone, \" f :\", f)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"19v-SsQWAwkF_s_-J0eB3c_PAsJVK_3eN"},"id":"P7HZUIHD_BCy","executionInfo":{"status":"ok","timestamp":1683090101601,"user_tz":-540,"elapsed":34261,"user":{"displayName":"박민수","userId":"07044323519487942912"}},"outputId":"c7d237b3-5f7e-474d-de2f-a4fff902604c"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.image import load_img\n","from tensorflow.keras.preprocessing.image import img_to_array\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","\n","from keras.models import load_model\n","\n","\n","img_height = 256\n","img_width = 256\n","\n","\n","# filename = ['../test_face/autumn_warm/face_000.jpg', \"../test_face/spring_warm/face_002.jpg\", \"../test_face/summer_cool/face_001.jpg\", \"../test_face/winter_cool/face_000.jpg\" ]\n","\n","filename = []\n","\n","path = \"../color_data2/color_tone_data_test/\"\n","img_list = os.listdir(path)\n","\n","for i in img_list:\n","  filename.append(path+i)\n","                    \n","predict_dictionary = {0:'cool',1:'warm'}\n","\n","tone_dict = {\n","    \"spring\": \"warm\",\n","    \"fall\": \"warm\",\n","    \"summer\": \"cool\",\n","    \"winter\": \"cool\"\n","}\n","\n","model_path = \"./resnet152v2_tone_best.h5\"\n","# model_path = \"./resnet50v2_final.h5\"\n","\n","model = load_model(model_path)\n","\n","answer_count = 0\n","f = 0\n","tone = 0\n","\n","a_list = []\n","f_list = []\n","\n","\n","# /color_data2/color_tone_data_test/fall (1).PNG \n","\n","for file in filename:\n","    original = load_img(file, target_size = (img_height,img_width))\n","\n","    \n","    numpy_image = img_to_array(original)\n","    plt.text(30, 10, str(file.split(\"/\")[-1]))\n","    plt.imshow(np.uint8(numpy_image))\n","    plt.show()\n","    print(\"numpy array size : \", numpy_image.shape)\n","    image_batch = np.expand_dims(numpy_image , axis = 0)\n","\n","    predict = np.argmax(model.predict(image_batch/255.))\n","\n","    print('결과 : ',predict_dictionary[predict])\n","    \n","    s1 = file.split(\"/\")[-1].split(\" \")[0]         \n","\n","    if predict_dictionary[predict] == tone_dict[s1]:\n","      tone += 1\n","    else:\n","      f += 1\n","\n","\n","print(\"answer :\", tone, \" f :\", f)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1EJZ5j-nzUaeXRKCduWPNEIq0196yqJmI"},"id":"2LHYWibwUNfZ","executionInfo":{"status":"ok","timestamp":1683095636977,"user_tz":-540,"elapsed":26643,"user":{"displayName":"박민수","userId":"07044323519487942912"}},"outputId":"dcec2cd3-2e0f-4ca8-a974-4b6792ba1c89"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["### 2. season test"],"metadata":{"id":"vRcLL6FRhyKq"}},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.image import load_img\n","from tensorflow.keras.preprocessing.image import img_to_array\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","\n","from keras.models import load_model\n","\n","\n","img_height = 256\n","img_width = 256\n","\n","\n","# filename = ['../test_face/autumn_warm/face_000.jpg', \"../test_face/spring_warm/face_002.jpg\", \"../test_face/summer_cool/face_001.jpg\", \"../test_face/winter_cool/face_000.jpg\" ]\n","\n","filename = []\n","\n","path = \"../color_data2/color_data_season_test/\"\n","img_list = os.listdir(path)\n","for i in img_list:\n","  filename.append(path+i)\n","                    \n","predict_dictionary = {0:'deep',1:'light'}\n","\n","tone_dict = {\n","    \"spring\": \"light\",\n","    \"fall\": \"deep\",\n","    \"summer\": \"light\",\n","    \"winter\": \"deep\"\n","}\n","\n","model_path = \"./resnet152v2_season_best.h5\"\n","# model_path = \"./resnet50v2_final.h5\"\n","\n","model = load_model(model_path)\n","\n","answer_count = 0\n","f = 0\n","tone = 0\n","\n","a_list = []\n","f_list = []\n","\n","for file in filename:\n","    original = load_img(file, target_size = (img_height,img_width))\n","\n","    \n","    numpy_image = img_to_array(original)\n","    plt.text(30, 10, str(file.split(\"/\")[-1]))\n","    plt.imshow(np.uint8(numpy_image))\n","    plt.show()\n","    print(\"numpy array size : \", numpy_image.shape)\n","    image_batch = np.expand_dims(numpy_image , axis = 0)\n","\n","    predict = np.argmax(model.predict(image_batch/255.))\n","\n","    print('결과 : ',predict_dictionary[predict])\n","\n","    s1 = file.split(\"/\")[-1].split(\" \")[0]         \n","\n","    if predict_dictionary[predict] == tone_dict[s1]:\n","      tone += 1\n","    else:\n","      f += 1\n","\n","\n","print(\"answer :\", tone, \" f :\", f)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1nvKB8Qdn1lDBE2YzlowVL6c2zfhkpzHL"},"id":"y27qdLMXOtXQ","executionInfo":{"status":"ok","timestamp":1683090067343,"user_tz":-540,"elapsed":26356,"user":{"displayName":"박민수","userId":"07044323519487942912"}},"outputId":"e456a870-b5ba-4f68-d6a7-74c363098d1f"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.image import load_img\n","from tensorflow.keras.preprocessing.image import img_to_array\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","\n","from keras.models import load_model\n","\n","\n","img_height = 256\n","img_width = 256\n","\n","\n","# filename = ['../test_face/autumn_warm/face_000.jpg', \"../test_face/spring_warm/face_002.jpg\", \"../test_face/summer_cool/face_001.jpg\", \"../test_face/winter_cool/face_000.jpg\" ]\n","\n","filename = []\n","\n","path = \"../color_data2/color_data_season_test/\"\n","img_list = os.listdir(path)\n","for i in img_list:\n","  filename.append(path+i)\n","                    \n","predict_dictionary = {0:'deep',1:'light'}\n","\n","tone_dict = {\n","    \"spring\": \"light\",\n","    \"fall\": \"deep\",\n","    \"summer\": \"light\",\n","    \"winter\": \"deep\"\n","}\n","\n","model_path = \"./resnet152v2_season_final.h5\"\n","# model_path = \"./resnet50v2_final.h5\"\n","\n","model = load_model(model_path)\n","\n","answer_count = 0\n","f = 0\n","tone = 0\n","\n","a_list = []\n","f_list = []\n","\n","for file in filename:\n","    original = load_img(file, target_size = (img_height,img_width))\n","\n","    \n","    numpy_image = img_to_array(original)\n","    plt.text(30, 10, str(file.split(\"/\")[-1]))\n","    plt.imshow(np.uint8(numpy_image))\n","    plt.show()\n","    print(\"numpy array size : \", numpy_image.shape)\n","    image_batch = np.expand_dims(numpy_image , axis = 0)\n","\n","    predict = np.argmax(model.predict(image_batch/255.))\n","\n","    print('결과 : ',predict_dictionary[predict])\n","\n","    s1 = file.split(\"/\")[-1].split(\" \")[0]         \n","\n","    if predict_dictionary[predict] == tone_dict[s1]:\n","      tone += 1\n","    else:\n","      f += 1\n","\n","\n","print(\"answer :\", tone, \" f :\", f)"],"metadata":{"id":"6OFbe6kiK9q1","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"105KWnJ6BQaW0iarWTETQ8l1UEHOJARiH"},"executionInfo":{"status":"ok","timestamp":1683090127564,"user_tz":-540,"elapsed":25966,"user":{"displayName":"박민수","userId":"07044323519487942912"}},"outputId":"813952f7-0d9f-4f58-abee-3d2715ad772b"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.image import load_img\n","from tensorflow.keras.preprocessing.image import img_to_array\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","\n","from keras.models import load_model\n","\n","\n","img_height = 256\n","img_width = 256\n","\n","\n","# filename = ['../test_face/autumn_warm/face_000.jpg', \"../test_face/spring_warm/face_002.jpg\", \"../test_face/summer_cool/face_001.jpg\", \"../test_face/winter_cool/face_000.jpg\" ]\n","\n","filename = []\n","\n","path = \"../color_data2/color_data_season_test/\"\n","img_list = os.listdir(path)\n","for i in img_list:\n","  filename.append(path+i)\n","                    \n","predict_dictionary = {0:'deep',1:'light'}\n","\n","tone_dict = {\n","    \"spring\": \"light\",\n","    \"fall\": \"deep\",\n","    \"summer\": \"light\",\n","    \"winter\": \"deep\"\n","}\n","\n","model_path = \"./resnet152v2_season_final.h5\"\n","# model_path = \"./resnet50v2_final.h5\"\n","\n","model = load_model(model_path)\n","\n","answer_count = 0\n","f = 0\n","tone = 0\n","\n","a_list = []\n","f_list = []\n","\n","for file in filename:\n","    original = load_img(file, target_size = (img_height,img_width))\n","\n","    \n","    numpy_image = img_to_array(original)\n","    plt.text(30, 10, str(file.split(\"/\")[-1]))\n","    plt.imshow(np.uint8(numpy_image))\n","    plt.show()\n","    print(\"numpy array size : \", numpy_image.shape)\n","    image_batch = np.expand_dims(numpy_image , axis = 0)\n","\n","    predict = np.argmax(model.predict(image_batch/255.))\n","\n","    print('결과 : ',predict_dictionary[predict])\n","\n","    s1 = file.split(\"/\")[-1].split(\" \")[0]         \n","\n","    if predict_dictionary[predict] == tone_dict[s1]:\n","      tone += 1\n","    else:\n","      f += 1\n","\n","\n","print(\"answer :\", tone, \" f :\", f)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1GLuB7ShSA-BWn1PyhiFYnRaGjd3-Nadh"},"id":"A4s3xsdUVSk-","executionInfo":{"status":"ok","timestamp":1683096222450,"user_tz":-540,"elapsed":27627,"user":{"displayName":"박민수","userId":"07044323519487942912"}},"outputId":"5ef03d27-c18f-4e32-8c47-fbbec336bf8f"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.image import load_img\n","from tensorflow.keras.preprocessing.image import img_to_array\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","\n","from keras.models import load_model\n","\n","\n","img_height = 256\n","img_width = 256\n","\n","\n","# filename = ['../test_face/autumn_warm/face_000.jpg', \"../test_face/spring_warm/face_002.jpg\", \"../test_face/summer_cool/face_001.jpg\", \"../test_face/winter_cool/face_000.jpg\" ]\n","\n","filename = []\n","\n","path = \"../color_data2/color_data_season_test/\"\n","img_list = os.listdir(path)\n","for i in img_list:\n","  filename.append(path+i)\n","                    \n","predict_dictionary = {0:'deep',1:'light'}\n","\n","tone_dict = {\n","    \"spring\": \"light\",\n","    \"fall\": \"deep\",\n","    \"summer\": \"light\",\n","    \"winter\": \"deep\"\n","}\n","\n","model_path = \"./resnet152v2_season_final.h5\"\n","# model_path = \"./resnet50v2_final.h5\"\n","\n","model = load_model(model_path)\n","\n","answer_count = 0\n","f = 0\n","tone = 0\n","\n","a_list = []\n","f_list = []\n","\n","for file in filename:\n","    original = load_img(file, target_size = (img_height,img_width))\n","\n","    \n","    numpy_image = img_to_array(original)\n","    plt.text(30, 10, str(file.split(\"/\")[-1]))\n","    plt.imshow(np.uint8(numpy_image))\n","    plt.show()\n","    print(\"numpy array size : \", numpy_image.shape)\n","    image_batch = np.expand_dims(numpy_image , axis = 0)\n","\n","    predict = np.argmax(model.predict(image_batch/255.))\n","\n","    print('결과 : ',predict_dictionary[predict])\n","\n","    s1 = file.split(\"/\")[-1].split(\" \")[0]         \n","\n","    if predict_dictionary[predict] == tone_dict[s1]:\n","      tone += 1\n","    else:\n","      f += 1\n","\n","\n","print(\"answer :\", tone, \" f :\", f)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1NKJ-YjzaApaI8P9-VmyY9Gq-GE7TZfJQ"},"id":"VDwpXnzfX1jl","executionInfo":{"status":"ok","timestamp":1683097564612,"user_tz":-540,"elapsed":26110,"user":{"displayName":"박민수","userId":"07044323519487942912"}},"outputId":"4d64fd6d-06e4-4fc7-883a-4e559e441699"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.image import load_img\n","from tensorflow.keras.preprocessing.image import img_to_array\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","\n","from keras.models import load_model\n","\n","\n","img_height = 256\n","img_width = 256\n","\n","\n","# filename = ['../test_face/autumn_warm/face_000.jpg', \"../test_face/spring_warm/face_002.jpg\", \"../test_face/summer_cool/face_001.jpg\", \"../test_face/winter_cool/face_000.jpg\" ]\n","\n","filename = []\n","\n","path = \"../color_data2/color_data_season_test/\"\n","img_list = os.listdir(path)\n","for i in img_list:\n","  filename.append(path+i)\n","                    \n","predict_dictionary = {0:'deep',1:'light'}\n","\n","tone_dict = {\n","    \"spring\": \"light\",\n","    \"fall\": \"deep\",\n","    \"summer\": \"light\",\n","    \"winter\": \"deep\"\n","}\n","\n","model_path = \"./resnet152v2_season_best.h5\"\n","# model_path = \"./resnet50v2_final.h5\"\n","\n","model = load_model(model_path)\n","\n","answer_count = 0\n","f = 0\n","tone = 0\n","\n","a_list = []\n","f_list = []\n","\n","for file in filename:\n","    original = load_img(file, target_size = (img_height,img_width))\n","\n","    \n","    numpy_image = img_to_array(original)\n","    plt.text(30, 10, str(file.split(\"/\")[-1]))\n","    plt.imshow(np.uint8(numpy_image))\n","    plt.show()\n","    print(\"numpy array size : \", numpy_image.shape)\n","    image_batch = np.expand_dims(numpy_image , axis = 0)\n","\n","    predict = np.argmax(model.predict(image_batch/255.))\n","\n","    print('결과 : ',predict_dictionary[predict])\n","\n","    s1 = file.split(\"/\")[-1].split(\" \")[0]         \n","\n","    if predict_dictionary[predict] == tone_dict[s1]:\n","      tone += 1\n","    else:\n","      f += 1\n","\n","\n","print(\"answer :\", tone, \" f :\", f)"],"metadata":{"id":"BwNhPKZuK9js","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1fgvhipOjfoFyj4NYWAU3w3A5_96f50gn"},"executionInfo":{"status":"ok","timestamp":1683102795268,"user_tz":-540,"elapsed":43347,"user":{"displayName":"박민수","userId":"07044323519487942912"}},"outputId":"6a5afce2-b804-4597-f3ac-22c8c08c816e"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.image import load_img\n","from tensorflow.keras.preprocessing.image import img_to_array\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","\n","from keras.models import load_model\n","\n","\n","img_height = 256\n","img_width = 256\n","\n","\n","# filename = ['../test_face/autumn_warm/face_000.jpg', \"../test_face/spring_warm/face_002.jpg\", \"../test_face/summer_cool/face_001.jpg\", \"../test_face/winter_cool/face_000.jpg\" ]\n","\n","filename = []\n","\n","path = \"../color_data2/color_data_season_test/\"\n","img_list = os.listdir(path)\n","for i in img_list:\n","  filename.append(path+i)\n","                    \n","predict_dictionary = {0:'deep',1:'light'}\n","\n","tone_dict = {\n","    \"spring\": \"light\",\n","    \"fall\": \"deep\",\n","    \"summer\": \"light\",\n","    \"winter\": \"deep\"\n","}\n","\n","model_path = \"./resnet152v2_season_final.h5\"\n","# model_path = \"./resnet50v2_final.h5\"\n","\n","model = load_model(model_path)\n","\n","answer_count = 0\n","f = 0\n","tone = 0\n","\n","a_list = []\n","f_list = []\n","\n","for file in filename:\n","    original = load_img(file, target_size = (img_height,img_width))\n","\n","    \n","    numpy_image = img_to_array(original)\n","    plt.text(30, 10, str(file.split(\"/\")[-1]))\n","    plt.imshow(np.uint8(numpy_image))\n","    plt.show()\n","    print(\"numpy array size : \", numpy_image.shape)\n","    image_batch = np.expand_dims(numpy_image , axis = 0)\n","\n","    predict = np.argmax(model.predict(image_batch/255.))\n","\n","    print('결과 : ',predict_dictionary[predict])\n","\n","    s1 = file.split(\"/\")[-1].split(\" \")[0]         \n","\n","    if predict_dictionary[predict] == tone_dict[s1]:\n","      tone += 1\n","    else:\n","      f += 1\n","\n","\n","print(\"answer :\", tone, \" f :\", f)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1ZdXUp_dNSsAJA_x5ym_-yNRxbVNzfmIj"},"id":"Pj2J3aRfu7q2","executionInfo":{"status":"ok","timestamp":1683102832021,"user_tz":-540,"elapsed":36755,"user":{"displayName":"박민수","userId":"07044323519487942912"}},"outputId":"1b275cf9-13dd-4db2-ba98-abab6db3940c"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"eqlSbZWpK9Bx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### tone -> season test"],"metadata":{"id":"lQMFfQwLDZwy"}},{"cell_type":"markdown","source":["#### 3. season spring autumn test"],"metadata":{"id":"bSR96P2LEyvf"}},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.image import load_img\n","from tensorflow.keras.preprocessing.image import img_to_array\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","\n","from keras.models import load_model\n","\n","\n","img_height = 256\n","img_width = 256\n","\n","\n","# filename = ['../test_face/autumn_warm/face_000.jpg', \"../test_face/spring_warm/face_002.jpg\", \"../test_face/summer_cool/face_001.jpg\", \"../test_face/winter_cool/face_000.jpg\" ]\n","\n","filename = []\n","\n","path = \"../color_data3/season_warm/test/\"\n","img_list = os.listdir(path)\n","for i in img_list:\n","  filename.append(path+i)\n","                    \n","\n","predict_dictionary = {0:'autumn',1:'spring'}\n","\n","tone_dict = {\n","    \"spring\": \"spring\",\n","    \"fall\": \"autumn\"\n","}\n","\n","model_path = \"./resnet152v2_season_spring_autumn_best.h5\"\n","# model_path = \"./resnet50v2_final.h5\"\n","\n","model = load_model(model_path)\n","\n","answer_count = 0\n","f = 0\n","tone = 0\n","\n","a_list = []\n","f_list = []\n","\n","for file in filename:\n","    original = load_img(file, target_size = (img_height,img_width))\n","\n","    \n","    numpy_image = img_to_array(original)\n","    plt.text(30, 10, str(file.split(\"/\")[-1]))\n","    plt.imshow(np.uint8(numpy_image))\n","    plt.show()\n","    print(\"numpy array size : \", numpy_image.shape)\n","    image_batch = np.expand_dims(numpy_image , axis = 0)\n","\n","    predict = np.argmax(model.predict(image_batch/255.))\n","\n","    print('결과 : ',predict_dictionary[predict])\n","\n","    s1 = file.split(\"/\")[-1].split(\" \")[0]         \n","\n","    if predict_dictionary[predict] == tone_dict[s1]:\n","      tone += 1\n","    else:\n","      f += 1\n","\n","\n","print(\"answer :\", tone, \" f :\", f)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1fnrCcLbX5TrsdqV5MyewJHwuQWPAljhB"},"id":"Uau7e3bpEzJ2","executionInfo":{"status":"ok","timestamp":1683093618228,"user_tz":-540,"elapsed":26266,"user":{"displayName":"박민수","userId":"07044323519487942912"}},"outputId":"5227c8c7-028a-41f9-9b25-ba81a24767d6"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.image import load_img\n","from tensorflow.keras.preprocessing.image import img_to_array\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","\n","from keras.models import load_model\n","\n","\n","img_height = 256\n","img_width = 256\n","\n","\n","# filename = ['../test_face/autumn_warm/face_000.jpg', \"../test_face/spring_warm/face_002.jpg\", \"../test_face/summer_cool/face_001.jpg\", \"../test_face/winter_cool/face_000.jpg\" ]\n","\n","filename = []\n","\n","path = \"../color_data3/season_warm/test/\"\n","img_list = os.listdir(path)\n","for i in img_list:\n","  filename.append(path+i)\n","                    \n","\n","predict_dictionary = {0:'autumn',1:'spring'}\n","\n","tone_dict = {\n","    \"spring\": \"spring\",\n","    \"fall\": \"autumn\"\n","}\n","\n","model_path = \"./resnet152v2_season_spring_autumn_best.h5\"\n","# model_path = \"./resnet50v2_final.h5\"\n","\n","model = load_model(model_path)\n","\n","answer_count = 0\n","f = 0\n","tone = 0\n","\n","a_list = []\n","f_list = []\n","\n","for file in filename:\n","    original = load_img(file, target_size = (img_height,img_width))\n","\n","    \n","    numpy_image = img_to_array(original)\n","    plt.text(30, 10, str(file.split(\"/\")[-1]))\n","    plt.imshow(np.uint8(numpy_image))\n","    plt.show()\n","    print(\"numpy array size : \", numpy_image.shape)\n","    image_batch = np.expand_dims(numpy_image , axis = 0)\n","\n","    predict = np.argmax(model.predict(image_batch/255.))\n","\n","    print('결과 : ',predict_dictionary[predict])\n","\n","    s1 = file.split(\"/\")[-1].split(\" \")[0]         \n","\n","    if predict_dictionary[predict] == tone_dict[s1]:\n","      tone += 1\n","    else:\n","      f += 1\n","\n","\n","print(\"answer :\", tone, \" f :\", f)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1hfa9pXcRq1bFmZfsIEmVCAsYjMSZXAYX"},"id":"0w-Iy9L7fQ3D","executionInfo":{"status":"ok","timestamp":1683098548156,"user_tz":-540,"elapsed":23199,"user":{"displayName":"박민수","userId":"07044323519487942912"}},"outputId":"94cfec34-0d73-493b-d8bc-9218be71cbb1"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.image import load_img\n","from tensorflow.keras.preprocessing.image import img_to_array\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","\n","from keras.models import load_model\n","\n","\n","img_height = 256\n","img_width = 256\n","\n","\n","# filename = ['../test_face/autumn_warm/face_000.jpg', \"../test_face/spring_warm/face_002.jpg\", \"../test_face/summer_cool/face_001.jpg\", \"../test_face/winter_cool/face_000.jpg\" ]\n","\n","filename = []\n","\n","path = \"../color_data3/season_warm/test/\"\n","img_list = os.listdir(path)\n","for i in img_list:\n","  filename.append(path+i)\n","                    \n","\n","predict_dictionary = {0:'autumn',1:'spring'}\n","\n","tone_dict = {\n","    \"spring\": \"spring\",\n","    \"fall\": \"autumn\"\n","}\n","\n","model_path = \"./resnet152v2_season_spring_autumn_final.h5\"\n","# model_path = \"./resnet50v2_final.h5\"\n","\n","model = load_model(model_path)\n","\n","answer_count = 0\n","f = 0\n","tone = 0\n","\n","a_list = []\n","f_list = []\n","\n","for file in filename:\n","    original = load_img(file, target_size = (img_height,img_width))\n","\n","    \n","    numpy_image = img_to_array(original)\n","    plt.text(30, 10, str(file.split(\"/\")[-1]))\n","    plt.imshow(np.uint8(numpy_image))\n","    plt.show()\n","    print(\"numpy array size : \", numpy_image.shape)\n","    image_batch = np.expand_dims(numpy_image , axis = 0)\n","\n","    predict = np.argmax(model.predict(image_batch/255.))\n","\n","    print('결과 : ',predict_dictionary[predict])\n","\n","    s1 = file.split(\"/\")[-1].split(\" \")[0]         \n","\n","    if predict_dictionary[predict] == tone_dict[s1]:\n","      tone += 1\n","    else:\n","      f += 1\n","\n","\n","print(\"answer :\", tone, \" f :\", f)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1iLT6yv364vlyDWwlLBmKND09GwC4dfcb"},"id":"Hgp6OhRNfqbS","executionInfo":{"status":"ok","timestamp":1683098645196,"user_tz":-540,"elapsed":26085,"user":{"displayName":"박민수","userId":"07044323519487942912"}},"outputId":"3ec468bf-5ae0-4781-efb9-a1378671d9ee"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","source":["#### 3. season winter summer test"],"metadata":{"id":"HnfZhtgdEzMd"}},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.image import load_img\n","from tensorflow.keras.preprocessing.image import img_to_array\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","\n","from keras.models import load_model\n","\n","\n","img_height = 256\n","img_width = 256\n","\n","\n","# filename = ['../test_face/autumn_warm/face_000.jpg', \"../test_face/spring_warm/face_002.jpg\", \"../test_face/summer_cool/face_001.jpg\", \"../test_face/winter_cool/face_000.jpg\" ]\n","\n","filename = []\n","\n","path = \"../color_data3/season_cool/test/\"\n","img_list = os.listdir(path)\n","for i in img_list:\n","  filename.append(path+i)\n","                    \n","\n","predict_dictionary = {0:'summer',1:'winter'}\n","\n","tone_dict = {\n","    \"summer\": \"summer\",\n","    \"winter\": \"winter\"\n","}\n","\n","model_path = \"./resnet152v2_season_winter_summer_best.h5\"\n","# model_path = \"./resnet50v2_final.h5\"\n","\n","model = load_model(model_path)\n","\n","answer_count = 0\n","f = 0\n","tone = 0\n","\n","a_list = []\n","f_list = []\n","\n","for file in filename:\n","    original = load_img(file, target_size = (img_height,img_width))\n","\n","    \n","    numpy_image = img_to_array(original)\n","    plt.text(30, 10, str(file.split(\"/\")[-1]))\n","    plt.imshow(np.uint8(numpy_image))\n","    plt.show()\n","    print(\"numpy array size : \", numpy_image.shape)\n","    image_batch = np.expand_dims(numpy_image , axis = 0)\n","\n","    predict = np.argmax(model.predict(image_batch/255.))\n","\n","    print('결과 : ',predict_dictionary[predict])\n","\n","    s1 = file.split(\"/\")[-1].split(\" \")[0]         \n","\n","    if predict_dictionary[predict] == tone_dict[s1]:\n","      tone += 1\n","    else:\n","      f += 1\n","\n","\n","print(\"answer :\", tone, \" f :\", f)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"17wWi-MPrJQZTSFFTb_iiiGFHZ12MZcZ6"},"id":"jH5Q0JneEzP0","executionInfo":{"status":"ok","timestamp":1683093661106,"user_tz":-540,"elapsed":29638,"user":{"displayName":"박민수","userId":"07044323519487942912"}},"outputId":"dda2b45b-cd2e-484f-e637-2afc60174b86"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.image import load_img\n","from tensorflow.keras.preprocessing.image import img_to_array\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","\n","from keras.models import load_model\n","\n","\n","img_height = 256\n","img_width = 256\n","\n","\n","# filename = ['../test_face/autumn_warm/face_000.jpg', \"../test_face/spring_warm/face_002.jpg\", \"../test_face/summer_cool/face_001.jpg\", \"../test_face/winter_cool/face_000.jpg\" ]\n","\n","filename = []\n","\n","path = \"../color_data3/season_cool/test/\"\n","img_list = os.listdir(path)\n","for i in img_list:\n","  filename.append(path+i)\n","                    \n","\n","predict_dictionary = {0:'summer',1:'winter'}\n","\n","tone_dict = {\n","    \"summer\": \"summer\",\n","    \"winter\": \"winter\"\n","}\n","\n","model_path = \"./resnet152v2_season_winter_summer_best.h5\"\n","# model_path = \"./resnet50v2_final.h5\"\n","\n","model = load_model(model_path)\n","\n","answer_count = 0\n","f = 0\n","tone = 0\n","\n","a_list = []\n","f_list = []\n","\n","for file in filename:\n","    original = load_img(file, target_size = (img_height,img_width))\n","\n","    \n","    numpy_image = img_to_array(original)\n","    plt.text(30, 10, str(file.split(\"/\")[-1]))\n","    plt.imshow(np.uint8(numpy_image))\n","    plt.show()\n","    print(\"numpy array size : \", numpy_image.shape)\n","    image_batch = np.expand_dims(numpy_image , axis = 0)\n","\n","    predict = np.argmax(model.predict(image_batch/255.))\n","\n","    print('결과 : ',predict_dictionary[predict])\n","\n","    s1 = file.split(\"/\")[-1].split(\" \")[0]         \n","\n","    if predict_dictionary[predict] == tone_dict[s1]:\n","      tone += 1\n","    else:\n","      f += 1\n","\n","\n","print(\"answer :\", tone, \" f :\", f)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1h2Ql6rpLd_nonORX5oCv_dLOZU6tIaJy"},"id":"Z1LzkKfQEzSa","executionInfo":{"status":"ok","timestamp":1683098619117,"user_tz":-540,"elapsed":30080,"user":{"displayName":"박민수","userId":"07044323519487942912"}},"outputId":"4c63435e-209c-448b-a8df-0307afc95e1d"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.image import load_img\n","from tensorflow.keras.preprocessing.image import img_to_array\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","\n","from keras.models import load_model\n","\n","\n","img_height = 256\n","img_width = 256\n","\n","\n","# filename = ['../test_face/autumn_warm/face_000.jpg', \"../test_face/spring_warm/face_002.jpg\", \"../test_face/summer_cool/face_001.jpg\", \"../test_face/winter_cool/face_000.jpg\" ]\n","\n","filename = []\n","\n","path = \"../color_data3/season_cool/test/\"\n","img_list = os.listdir(path)\n","for i in img_list:\n","  filename.append(path+i)\n","                    \n","\n","predict_dictionary = {0:'summer',1:'winter'}\n","\n","tone_dict = {\n","    \"summer\": \"summer\",\n","    \"winter\": \"winter\"\n","}\n","\n","model_path = \"./resnet152v2_season_winter_summer_final.h5\"\n","# model_path = \"./resnet50v2_final.h5\"\n","\n","model = load_model(model_path)\n","\n","answer_count = 0\n","f = 0\n","tone = 0\n","\n","a_list = []\n","f_list = []\n","\n","for file in filename:\n","    original = load_img(file, target_size = (img_height,img_width))\n","\n","    \n","    numpy_image = img_to_array(original)\n","    plt.text(30, 10, str(file.split(\"/\")[-1]))\n","    plt.imshow(np.uint8(numpy_image))\n","    plt.show()\n","    print(\"numpy array size : \", numpy_image.shape)\n","    image_batch = np.expand_dims(numpy_image , axis = 0)\n","\n","    predict = np.argmax(model.predict(image_batch/255.))\n","\n","    print('결과 : ',predict_dictionary[predict])\n","\n","    s1 = file.split(\"/\")[-1].split(\" \")[0]         \n","\n","    if predict_dictionary[predict] == tone_dict[s1]:\n","      tone += 1\n","    else:\n","      f += 1\n","\n","\n","print(\"answer :\", tone, \" f :\", f)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1_P__OVpZULo5Um6APMRU7QlVFzVswCu3"},"id":"_4zz4yS0ftvb","executionInfo":{"status":"ok","timestamp":1683098669731,"user_tz":-540,"elapsed":24553,"user":{"displayName":"박민수","userId":"07044323519487942912"}},"outputId":"951442b2-8c09-4d39-a8ec-df7502e45bcc"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}